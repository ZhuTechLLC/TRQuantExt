"""
Aè‚¡ä¸»çº¿è¯†åˆ« - ä¸“ä¸šåˆ†æå¼•æ“

å‚è€ƒPandaAIå’Œæœºæ„çº§é‡åŒ–å¹³å°æ¶æ„è®¾è®¡ï¼š
1. å¤šæ•°æ®æºç»Ÿä¸€æ¥å…¥ï¼ˆAKShare/TuShare/JQData/Windï¼‰
2. æœ¬åœ°ç¼“å­˜å±‚ï¼ˆMongoDB + æ–‡ä»¶ï¼‰
3. äº‹ä»¶é©±åŠ¨åˆ†ææ¡†æ¶
4. Cursor IDEé›†æˆåˆ†æ
5. å¯è§†åŒ–å·¥ä½œæµ

æ ¸å¿ƒç†å¿µï¼š
- æ•°æ®é©±åŠ¨ï¼šæ‰€æœ‰ç»“è®ºåŸºäºçœŸå®æ•°æ®
- è¿‡ç¨‹é€æ˜ï¼šæ¯ä¸€æ­¥åˆ†æéƒ½å¯è¿½æº¯
- AIè¾…åŠ©ï¼šåˆ©ç”¨LLMå¢å¼ºåˆ†æèƒ½åŠ›
- å·¥å…·é›†æˆï¼šä¸Cursor/IDEæ— ç¼åä½œ
"""

import os
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum

from .real_data_fetcher import RealDataFetcher, real_data_fetcher, DataFetchResult

logger = logging.getLogger(__name__)


class AnalysisStage(Enum):
    """åˆ†æé˜¶æ®µ"""
    DATA_COLLECTION = "data_collection"      # æ•°æ®é‡‡é›†
    DATA_VALIDATION = "data_validation"      # æ•°æ®éªŒè¯
    MACRO_ANALYSIS = "macro_analysis"        # å®è§‚åˆ†æ
    SECTOR_ANALYSIS = "sector_analysis"      # æ¿å—åˆ†æ
    CAPITAL_ANALYSIS = "capital_analysis"    # èµ„é‡‘åˆ†æ
    SENTIMENT_ANALYSIS = "sentiment_analysis"  # æƒ…ç»ªåˆ†æ
    MAINLINE_SYNTHESIS = "mainline_synthesis"  # ä¸»çº¿ç»¼åˆ
    REPORT_GENERATION = "report_generation"   # æŠ¥å‘Šç”Ÿæˆ


@dataclass
class AnalysisStep:
    """åˆ†ææ­¥éª¤è®°å½•"""
    stage: AnalysisStage
    name: str
    start_time: datetime
    end_time: Optional[datetime] = None
    input_data: Optional[Dict] = None
    output_data: Optional[Any] = None
    data_sources: List[str] = field(default_factory=list)
    method: str = ""
    status: str = "running"
    error: Optional[str] = None
    
    def complete(self, output: Any):
        self.end_time = datetime.now()
        self.output_data = output
        self.status = "completed"
    
    def fail(self, error: str):
        self.end_time = datetime.now()
        self.error = error
        self.status = "failed"
    
    @property
    def duration_ms(self) -> int:
        if self.end_time:
            return int((self.end_time - self.start_time).total_seconds() * 1000)
        return 0
    
    def to_dict(self) -> Dict:
        return {
            "stage": self.stage.value,
            "name": self.name,
            "start_time": self.start_time.isoformat(),
            "end_time": self.end_time.isoformat() if self.end_time else None,
            "duration_ms": self.duration_ms,
            "data_sources": self.data_sources,
            "method": self.method,
            "status": self.status,
            "error": self.error,
        }


@dataclass
class MainlineResult:
    """ä¸»çº¿è¯†åˆ«ç»“æœ"""
    name: str
    score: float
    confidence: float
    core_logic: str
    supporting_factors: List[Dict]
    risk_factors: List[str]
    sectors: List[str]
    leading_stocks: List[str]
    data_evidence: List[Dict]  # æ•°æ®è¯æ®
    analysis_chain: List[str]  # åˆ†ææ¨ç†é“¾
    recommendation: str
    
    def to_dict(self) -> Dict:
        return {
            "name": self.name,
            "score": self.score,
            "confidence": self.confidence,
            "core_logic": self.core_logic,
            "supporting_factors": self.supporting_factors,
            "risk_factors": self.risk_factors,
            "sectors": self.sectors,
            "leading_stocks": self.leading_stocks,
            "data_evidence": self.data_evidence,
            "analysis_chain": self.analysis_chain,
            "recommendation": self.recommendation,
        }


class MainlineAnalysisEngine:
    """
    ä¸»çº¿åˆ†æå¼•æ“
    
    å‚è€ƒPandaAIçš„å·¥ä½œæµæ¶æ„å’Œæœºæ„çº§é‡åŒ–å¹³å°è®¾è®¡ï¼š
    1. æ•°æ®é‡‡é›† â†’ 2. æ•°æ®éªŒè¯ â†’ 3. å¤šç»´åˆ†æ â†’ 4. ä¸»çº¿ç»¼åˆ â†’ 5. æŠ¥å‘Šç”Ÿæˆ
    
    æ¯ä¸ªæ­¥éª¤éƒ½è®°å½•ï¼š
    - ä½¿ç”¨çš„æ•°æ®æº
    - åˆ†ææ–¹æ³•
    - è¾“å…¥è¾“å‡º
    - æ‰§è¡Œæ—¶é—´
    """
    
    def __init__(self, data_fetcher: Optional[RealDataFetcher] = None):
        self.data_fetcher = data_fetcher or real_data_fetcher
        self.steps: List[AnalysisStep] = []
        self.raw_data: Dict[str, DataFetchResult] = {}
        self.analysis_results: Dict[str, Any] = {}
        self.mainlines: List[MainlineResult] = []
        
        # åˆ†æé…ç½®
        self.config = {
            "min_sector_count": 5,           # æœ€å°‘æ¿å—æ•°
            "top_sector_count": 10,          # å–å‰Nä¸ªæ¿å—
            "mainline_threshold": 60,        # ä¸»çº¿å¾—åˆ†é˜ˆå€¼
            "confidence_threshold": 0.7,     # ç½®ä¿¡åº¦é˜ˆå€¼
        }
    
    def run_full_analysis(self) -> Dict:
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        
        Returns:
            {
                "mainlines": List[MainlineResult],
                "steps": List[AnalysisStep],
                "raw_data": Dict,
                "analysis_results": Dict,
                "summary": Dict,
                "cursor_prompt": str,
            }
        """
        self.steps = []
        self.raw_data = {}
        self.analysis_results = {}
        self.mainlines = []
        
        start_time = datetime.now()
        logger.info("=" * 70)
        logger.info("ğŸš€ å¼€å§‹ä¸»çº¿åˆ†æå¼•æ“")
        logger.info("=" * 70)
        
        try:
            # Step 1: æ•°æ®é‡‡é›†
            self._step_data_collection()
            
            # Step 2: æ•°æ®éªŒè¯
            self._step_data_validation()
            
            # Step 3: æ¿å—åˆ†æ
            self._step_sector_analysis()
            
            # Step 4: èµ„é‡‘åˆ†æ
            self._step_capital_analysis()
            
            # Step 5: æƒ…ç»ªåˆ†æ
            self._step_sentiment_analysis()
            
            # Step 6: ä¸»çº¿ç»¼åˆ
            self._step_mainline_synthesis()
            
            # Step 7: ç”ŸæˆCursoråˆ†æPrompt
            cursor_prompt = self._generate_cursor_prompt()
            
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            cursor_prompt = f"åˆ†æå¤±è´¥: {e}"
        
        total_time = (datetime.now() - start_time).total_seconds() * 1000
        
        # ç”Ÿæˆæ‘˜è¦
        summary = {
            "total_time_ms": int(total_time),
            "steps_completed": len([s for s in self.steps if s.status == "completed"]),
            "steps_failed": len([s for s in self.steps if s.status == "failed"]),
            "data_sources_used": list(set(
                src for step in self.steps for src in step.data_sources
            )),
            "mainlines_found": len(self.mainlines),
            "analysis_time": datetime.now().isoformat(),
        }
        
        logger.info("=" * 70)
        logger.info(f"âœ… åˆ†æå®Œæˆï¼Œè€—æ—¶ {total_time:.0f}ms")
        logger.info(f"   å‘ç° {len(self.mainlines)} æ¡ä¸»çº¿")
        logger.info("=" * 70)
        
        return {
            "mainlines": self.mainlines,
            "steps": self.steps,
            "raw_data": self.raw_data,
            "analysis_results": self.analysis_results,
            "summary": summary,
            "cursor_prompt": cursor_prompt,
        }
    
    def _start_step(self, stage: AnalysisStage, name: str, method: str = "") -> AnalysisStep:
        """å¼€å§‹ä¸€ä¸ªåˆ†ææ­¥éª¤"""
        step = AnalysisStep(
            stage=stage,
            name=name,
            start_time=datetime.now(),
            method=method,
        )
        self.steps.append(step)
        logger.info(f"\nğŸ“Œ {name}")
        return step
    
    # ================================================================
    # Step 1: æ•°æ®é‡‡é›†
    # ================================================================
    
    def _step_data_collection(self):
        """æ•°æ®é‡‡é›†æ­¥éª¤"""
        step = self._start_step(
            AnalysisStage.DATA_COLLECTION,
            "æ•°æ®é‡‡é›†",
            "ä»AKShare/MongoDBè·å–å®æ—¶å¸‚åœºæ•°æ®"
        )
        
        try:
            self.raw_data = self.data_fetcher.fetch_all_data()
            
            step.data_sources = [
                f"{key}:{result.source}" 
                for key, result in self.raw_data.items()
            ]
            
            success_count = sum(1 for r in self.raw_data.values() if r.success)
            step.complete({
                "total": len(self.raw_data),
                "success": success_count,
                "sources": step.data_sources,
            })
            
            logger.info(f"   âœ… {success_count}/{len(self.raw_data)} æ•°æ®æºæˆåŠŸ")
            
        except Exception as e:
            step.fail(str(e))
            raise
    
    # ================================================================
    # Step 2: æ•°æ®éªŒè¯
    # ================================================================
    
    def _step_data_validation(self):
        """æ•°æ®éªŒè¯æ­¥éª¤"""
        step = self._start_step(
            AnalysisStage.DATA_VALIDATION,
            "æ•°æ®éªŒè¯",
            "æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å’Œæ—¶æ•ˆæ€§"
        )
        
        try:
            validation_results = {}
            
            for key, result in self.raw_data.items():
                validation = {
                    "source": result.source,
                    "success": result.success,
                    "has_data": result.data is not None,
                    "data_count": len(result.data) if isinstance(result.data, list) else 1 if result.data else 0,
                    "fetch_time": result.fetch_time.isoformat(),
                    "is_fresh": (datetime.now() - result.fetch_time).seconds < 3600,  # 1å°æ—¶å†…
                }
                validation_results[key] = validation
            
            step.data_sources = list(self.raw_data.keys())
            step.complete(validation_results)
            
            fresh_count = sum(1 for v in validation_results.values() if v["is_fresh"])
            logger.info(f"   âœ… {fresh_count}/{len(validation_results)} æ•°æ®æ–°é²œ")
            
        except Exception as e:
            step.fail(str(e))
            raise
    
    # ================================================================
    # Step 3: æ¿å—åˆ†æ
    # ================================================================
    
    def _step_sector_analysis(self):
        """æ¿å—åˆ†ææ­¥éª¤"""
        step = self._start_step(
            AnalysisStage.SECTOR_ANALYSIS,
            "æ¿å—åˆ†æ",
            "åˆ†ææ¿å—æ¶¨è·Œã€èµ„é‡‘æµå‘ã€é¾™å¤´è¡¨ç°"
        )
        step.data_sources = ["sector_flow", "concept_board"]
        
        try:
            sector_flow = self.raw_data.get("sector_flow")
            concept_board = self.raw_data.get("concept_board")
            
            analysis = {
                "top_sectors": [],
                "hot_concepts": [],
                "sector_rotation": "",
                "leading_themes": [],
            }
            
            # åˆ†ææ¿å—èµ„é‡‘æµå‘
            if sector_flow and sector_flow.success and sector_flow.data:
                sorted_sectors = sorted(
                    sector_flow.data, 
                    key=lambda x: x.get("main_net_inflow", 0), 
                    reverse=True
                )
                analysis["top_sectors"] = sorted_sectors[:self.config["top_sector_count"]]
                
                # åˆ¤æ–­æ¿å—è½®åŠ¨
                inflow_sectors = [s["sector_name"] for s in sorted_sectors if s.get("main_net_inflow", 0) > 0]
                outflow_sectors = [s["sector_name"] for s in sorted_sectors if s.get("main_net_inflow", 0) < 0]
                
                if "ç§‘æŠ€" in str(inflow_sectors) or "äººå·¥æ™ºèƒ½" in str(inflow_sectors):
                    analysis["sector_rotation"] = "ç§‘æŠ€æˆé•¿ä¸»å¯¼"
                elif "æ¶ˆè´¹" in str(inflow_sectors):
                    analysis["sector_rotation"] = "æ¶ˆè´¹å¤è‹"
                elif "é‡‘è" in str(inflow_sectors) or "é“¶è¡Œ" in str(inflow_sectors):
                    analysis["sector_rotation"] = "å¤§é‡‘èå‘åŠ›"
                else:
                    analysis["sector_rotation"] = "æ¿å—è½®åŠ¨"
            
            # åˆ†ææ¦‚å¿µæ¿å—
            if concept_board and concept_board.success and concept_board.data:
                sorted_concepts = sorted(
                    concept_board.data,
                    key=lambda x: x.get("change_pct", 0),
                    reverse=True
                )
                analysis["hot_concepts"] = sorted_concepts[:10]
                
                # æå–ä¸»é¢˜
                for concept in sorted_concepts[:5]:
                    name = concept.get("board_name", "")
                    if "AI" in name or "æ™ºèƒ½" in name or "ChatGPT" in name:
                        analysis["leading_themes"].append("äººå·¥æ™ºèƒ½")
                    elif "èŠ¯ç‰‡" in name or "åŠå¯¼ä½“" in name:
                        analysis["leading_themes"].append("åŠå¯¼ä½“")
                    elif "å…‰" in name and "æ¨¡å—" in name:
                        analysis["leading_themes"].append("å…‰æ¨¡å—")
                    elif "æœºå™¨äºº" in name:
                        analysis["leading_themes"].append("æœºå™¨äºº")
                    elif "æ–°èƒ½æº" in name or "å…‰ä¼" in name:
                        analysis["leading_themes"].append("æ–°èƒ½æº")
                
                analysis["leading_themes"] = list(set(analysis["leading_themes"]))
            
            self.analysis_results["sector"] = analysis
            step.complete(analysis)
            
            logger.info(f"   âœ… æ¿å—è½®åŠ¨: {analysis['sector_rotation']}")
            logger.info(f"   âœ… ä¸»å¯¼ä¸»é¢˜: {analysis['leading_themes']}")
            
        except Exception as e:
            step.fail(str(e))
            raise
    
    # ================================================================
    # Step 4: èµ„é‡‘åˆ†æ
    # ================================================================
    
    def _step_capital_analysis(self):
        """èµ„é‡‘åˆ†ææ­¥éª¤"""
        step = self._start_step(
            AnalysisStage.CAPITAL_ANALYSIS,
            "èµ„é‡‘åˆ†æ",
            "åˆ†æåŒ—å‘èµ„é‡‘ã€ä¸»åŠ›èµ„é‡‘æµå‘"
        )
        step.data_sources = ["northbound_flow", "sector_flow"]
        
        try:
            northbound = self.raw_data.get("northbound_flow")
            sector_flow = self.raw_data.get("sector_flow")
            
            analysis = {
                "northbound_trend": "",
                "northbound_data": {},
                "main_force_direction": [],
                "capital_consensus": [],
            }
            
            # åŒ—å‘èµ„é‡‘åˆ†æ
            if northbound and northbound.success and northbound.data:
                data = northbound.data
                today = data.get("today_net", 0)
                week = data.get("week_net", 0)
                month = data.get("month_net", 0)
                
                analysis["northbound_data"] = {
                    "today": today,
                    "week": week,
                    "month": month,
                }
                
                if month > 100:
                    analysis["northbound_trend"] = "å¤§å¹…æµå…¥"
                elif month > 0:
                    analysis["northbound_trend"] = "æ¸©å’Œæµå…¥"
                elif month > -100:
                    analysis["northbound_trend"] = "æ¸©å’Œæµå‡º"
                else:
                    analysis["northbound_trend"] = "å¤§å¹…æµå‡º"
            
            # ä¸»åŠ›èµ„é‡‘æ–¹å‘
            if sector_flow and sector_flow.success and sector_flow.data:
                inflow_sectors = [
                    s["sector_name"] 
                    for s in sector_flow.data 
                    if s.get("main_net_inflow", 0) > 10  # è¶…è¿‡10äº¿
                ]
                analysis["main_force_direction"] = inflow_sectors[:5]
                
                # èµ„é‡‘å…±è¯†
                if len(inflow_sectors) >= 3:
                    analysis["capital_consensus"] = inflow_sectors[:3]
            
            self.analysis_results["capital"] = analysis
            step.complete(analysis)
            
            logger.info(f"   âœ… åŒ—å‘è¶‹åŠ¿: {analysis['northbound_trend']}")
            logger.info(f"   âœ… ä¸»åŠ›æ–¹å‘: {analysis['main_force_direction']}")
            
        except Exception as e:
            step.fail(str(e))
            raise
    
    # ================================================================
    # Step 5: æƒ…ç»ªåˆ†æ
    # ================================================================
    
    def _step_sentiment_analysis(self):
        """æƒ…ç»ªåˆ†ææ­¥éª¤"""
        step = self._start_step(
            AnalysisStage.SENTIMENT_ANALYSIS,
            "æƒ…ç»ªåˆ†æ",
            "åˆ†ææ¶¨åœè·Œåœã€è¿æ¿ã€å¸‚åœºæƒ…ç»ª"
        )
        step.data_sources = ["market_sentiment", "dragon_tiger"]
        
        try:
            sentiment = self.raw_data.get("market_sentiment")
            dragon = self.raw_data.get("dragon_tiger")
            
            analysis = {
                "sentiment_score": 50,
                "sentiment_level": "ä¸­æ€§",
                "limit_up_count": 0,
                "limit_down_count": 0,
                "continuous_limit": {},
                "hot_stocks": [],
            }
            
            if sentiment and sentiment.success and sentiment.data:
                data = sentiment.data
                analysis["sentiment_score"] = data.get("sentiment_score", 50)
                analysis["limit_up_count"] = data.get("up_limit_count", 0)
                analysis["limit_down_count"] = data.get("down_limit_count", 0)
                analysis["continuous_limit"] = data.get("continuous_limit", {})
                
                score = analysis["sentiment_score"]
                if score >= 80:
                    analysis["sentiment_level"] = "æåº¦ä¹è§‚"
                elif score >= 65:
                    analysis["sentiment_level"] = "ä¹è§‚"
                elif score >= 50:
                    analysis["sentiment_level"] = "ä¸­æ€§åå¤š"
                elif score >= 35:
                    analysis["sentiment_level"] = "è°¨æ…"
                else:
                    analysis["sentiment_level"] = "æ‚²è§‚"
            
            if dragon and dragon.success and dragon.data:
                analysis["hot_stocks"] = [
                    {"name": d.get("name", ""), "reason": d.get("reason", "")}
                    for d in dragon.data[:5]
                ]
            
            self.analysis_results["sentiment"] = analysis
            step.complete(analysis)
            
            logger.info(f"   âœ… æƒ…ç»ªå¾—åˆ†: {analysis['sentiment_score']}")
            logger.info(f"   âœ… æƒ…ç»ªæ°´å¹³: {analysis['sentiment_level']}")
            
        except Exception as e:
            step.fail(str(e))
            raise
    
    # ================================================================
    # Step 6: ä¸»çº¿ç»¼åˆ
    # ================================================================
    
    def _step_mainline_synthesis(self):
        """ä¸»çº¿ç»¼åˆæ­¥éª¤"""
        step = self._start_step(
            AnalysisStage.MAINLINE_SYNTHESIS,
            "ä¸»çº¿ç»¼åˆ",
            "ç»¼åˆå¤šç»´åº¦æ•°æ®è¯†åˆ«æŠ•èµ„ä¸»çº¿"
        )
        step.data_sources = ["sector", "capital", "sentiment"]
        
        try:
            sector = self.analysis_results.get("sector", {})
            capital = self.analysis_results.get("capital", {})
            sentiment = self.analysis_results.get("sentiment", {})
            
            # è¯†åˆ«ä¸»çº¿
            mainlines = []
            
            # ä¸»çº¿1: äººå·¥æ™ºèƒ½
            if "äººå·¥æ™ºèƒ½" in sector.get("leading_themes", []):
                mainline = self._build_mainline(
                    name="äººå·¥æ™ºèƒ½é©å‘½",
                    base_score=85,
                    core_logic="AIå¤§æ¨¡å‹æŠ€æœ¯çªç ´å¼•å‘æ–°ä¸€è½®ç§‘æŠ€é©å‘½",
                    sectors=["AIç®—åŠ›", "AIåº”ç”¨", "å…‰æ¨¡å—", "æ•°æ®ä¸­å¿ƒ"],
                    stocks=["å¯’æ­¦çºª", "ä¸­ç§‘æ›™å…‰", "ç§‘å¤§è®¯é£", "ä¸­é™…æ—­åˆ›"],
                    sector_data=sector,
                    capital_data=capital,
                    sentiment_data=sentiment,
                )
                mainlines.append(mainline)
            
            # ä¸»çº¿2: åŠå¯¼ä½“/å›½äº§æ›¿ä»£
            if "åŠå¯¼ä½“" in sector.get("leading_themes", []):
                mainline = self._build_mainline(
                    name="å›½äº§æ›¿ä»£åŠ é€Ÿ",
                    base_score=80,
                    core_logic="å¤–éƒ¨å‹åŠ›å€’é€¼å›½äº§åŒ–è¿›ç¨‹ï¼ŒåŠå¯¼ä½“è®¾å¤‡ææ–™å—ç›Š",
                    sectors=["åŠå¯¼ä½“è®¾å¤‡", "åŠå¯¼ä½“ææ–™", "EDA", "å…ˆè¿›å°è£…"],
                    stocks=["åŒ—æ–¹ååˆ›", "ä¸­å¾®å…¬å¸", "åå¤§ä¹å¤©", "é•¿ç”µç§‘æŠ€"],
                    sector_data=sector,
                    capital_data=capital,
                    sentiment_data=sentiment,
                )
                mainlines.append(mainline)
            
            # ä¸»çº¿3: æ–°èƒ½æº
            if "æ–°èƒ½æº" in sector.get("leading_themes", []):
                mainline = self._build_mainline(
                    name="æ–°èƒ½æºè½¬å‹",
                    base_score=70,
                    core_logic="ç¢³ä¸­å’Œç›®æ ‡é©±åŠ¨èƒ½æºç»“æ„è½¬å‹",
                    sectors=["å…‰ä¼", "å‚¨èƒ½", "é”‚ç”µæ± ", "æ–°èƒ½æºè½¦"],
                    stocks=["éš†åŸºç»¿èƒ½", "å®å¾·æ—¶ä»£", "é˜³å…‰ç”µæº", "æ¯”äºšè¿ª"],
                    sector_data=sector,
                    capital_data=capital,
                    sentiment_data=sentiment,
                )
                mainlines.append(mainline)
            
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ä¸»çº¿ï¼Œæ·»åŠ é»˜è®¤ä¸»çº¿
            if not mainlines:
                mainline = self._build_mainline(
                    name="ç§‘æŠ€æˆé•¿",
                    base_score=65,
                    core_logic="æ”¿ç­–æ”¯æŒç§‘æŠ€åˆ›æ–°ï¼Œæˆé•¿é£æ ¼å ä¼˜",
                    sectors=["ç§‘æŠ€", "ç”µå­", "è®¡ç®—æœº"],
                    stocks=["å¾…ç­›é€‰"],
                    sector_data=sector,
                    capital_data=capital,
                    sentiment_data=sentiment,
                )
                mainlines.append(mainline)
            
            # æŒ‰å¾—åˆ†æ’åº
            mainlines.sort(key=lambda x: x.score, reverse=True)
            self.mainlines = mainlines
            
            step.complete({
                "mainlines_count": len(mainlines),
                "top_mainline": mainlines[0].name if mainlines else None,
            })
            
            for ml in mainlines:
                logger.info(f"   ğŸ”¥ {ml.name}: {ml.score:.0f}åˆ†")
            
        except Exception as e:
            step.fail(str(e))
            raise
    
    def _build_mainline(
        self,
        name: str,
        base_score: float,
        core_logic: str,
        sectors: List[str],
        stocks: List[str],
        sector_data: Dict,
        capital_data: Dict,
        sentiment_data: Dict,
    ) -> MainlineResult:
        """æ„å»ºä¸»çº¿ç»“æœ"""
        
        # è®¡ç®—è°ƒæ•´åå¾—åˆ†
        score = base_score
        confidence = 0.7
        supporting_factors = []
        analysis_chain = []
        data_evidence = []
        
        # 1. æ¿å—å› ç´ 
        top_sectors = sector_data.get("top_sectors", [])
        for sector in sectors:
            for ts in top_sectors:
                if sector in ts.get("sector_name", ""):
                    score += 3
                    confidence += 0.05
                    supporting_factors.append({
                        "factor": f"æ¿å—èµ„é‡‘æµå…¥",
                        "detail": f"{ts['sector_name']}ä¸»åŠ›å‡€æµå…¥{ts.get('main_net_inflow', 0):.1f}äº¿",
                        "score_impact": 3,
                    })
                    data_evidence.append({
                        "source": "sector_flow",
                        "data": f"{ts['sector_name']}: {ts.get('change_pct', 0):.2f}%",
                    })
                    break
        
        analysis_chain.append(f"æ¿å—åˆ†æ: {sector_data.get('sector_rotation', 'æœªçŸ¥')}")
        
        # 2. èµ„é‡‘å› ç´ 
        northbound_trend = capital_data.get("northbound_trend", "")
        if "æµå…¥" in northbound_trend:
            score += 5
            confidence += 0.05
            supporting_factors.append({
                "factor": "åŒ—å‘èµ„é‡‘æµå…¥",
                "detail": northbound_trend,
                "score_impact": 5,
            })
            data_evidence.append({
                "source": "northbound_flow",
                "data": f"æœ¬æœˆå‡€æµå…¥: {capital_data.get('northbound_data', {}).get('month', 0):.1f}äº¿",
            })
        
        analysis_chain.append(f"èµ„é‡‘åˆ†æ: {northbound_trend}")
        
        # 3. æƒ…ç»ªå› ç´ 
        sentiment_level = sentiment_data.get("sentiment_level", "ä¸­æ€§")
        sentiment_score = sentiment_data.get("sentiment_score", 50)
        if sentiment_score >= 65:
            score += 5
            confidence += 0.05
            supporting_factors.append({
                "factor": "å¸‚åœºæƒ…ç»ªä¹è§‚",
                "detail": f"æƒ…ç»ªå¾—åˆ†{sentiment_score}",
                "score_impact": 5,
            })
        
        data_evidence.append({
            "source": "market_sentiment",
            "data": f"æ¶¨åœ{sentiment_data.get('limit_up_count', 0)}å®¶ï¼Œè·Œåœ{sentiment_data.get('limit_down_count', 0)}å®¶",
        })
        
        analysis_chain.append(f"æƒ…ç»ªåˆ†æ: {sentiment_level}")
        
        # é£é™©å› ç´ 
        risk_factors = []
        if score > 85:
            risk_factors.append("ä¼°å€¼å¯èƒ½åé«˜")
        if sentiment_score > 80:
            risk_factors.append("å¸‚åœºè¿‡çƒ­é£é™©")
        if "æµå‡º" in northbound_trend:
            risk_factors.append("å¤–èµ„æµå‡ºå‹åŠ›")
        
        # æŠ•èµ„å»ºè®®
        if score >= 85:
            recommendation = "å¼ºçƒˆæ¨èï¼šå¤šç»´åº¦æŒ‡æ ‡ä¼˜å¼‚ï¼Œå»ºè®®ç§¯æé…ç½®"
        elif score >= 75:
            recommendation = "æ¨èï¼šæ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®é€‚åº¦è¶…é…"
        elif score >= 65:
            recommendation = "ä¸­æ€§åå¤šï¼šåŸºæœ¬é¢å°šå¯ï¼Œå»ºè®®æ ‡é…"
        else:
            recommendation = "è§‚æœ›ï¼šç­‰å¾…æ›´æ˜ç¡®ä¿¡å·"
        
        return MainlineResult(
            name=name,
            score=min(100, score),
            confidence=min(1.0, confidence),
            core_logic=core_logic,
            supporting_factors=supporting_factors,
            risk_factors=risk_factors,
            sectors=sectors,
            leading_stocks=stocks,
            data_evidence=data_evidence,
            analysis_chain=analysis_chain,
            recommendation=recommendation,
        )
    
    # ================================================================
    # ç”ŸæˆCursoråˆ†æPrompt
    # ================================================================
    
    def _generate_cursor_prompt(self) -> str:
        """ç”Ÿæˆä¾›Cursoråˆ†æçš„Prompt"""
        
        # æ”¶é›†æ‰€æœ‰æ•°æ®
        sector = self.analysis_results.get("sector", {})
        capital = self.analysis_results.get("capital", {})
        sentiment = self.analysis_results.get("sentiment", {})
        
        prompt = f"""# Aè‚¡ä¸»çº¿è¯†åˆ«åˆ†æè¯·æ±‚

## ğŸ“… åˆ†ææ—¶é—´
{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š çœŸå®å¸‚åœºæ•°æ®æ‘˜è¦

### æ¿å—èµ„é‡‘æµå‘
"""
        
        # æ·»åŠ æ¿å—æ•°æ®
        top_sectors = sector.get("top_sectors", [])
        if top_sectors:
            prompt += "| æ¿å— | æ¶¨è·Œå¹… | ä¸»åŠ›å‡€æµå…¥(äº¿) |\n"
            prompt += "|------|--------|----------------|\n"
            for s in top_sectors[:10]:
                prompt += f"| {s.get('sector_name', '')} | {s.get('change_pct', 0):.2f}% | {s.get('main_net_inflow', 0):.2f} |\n"
        
        prompt += f"""
### åŒ—å‘èµ„é‡‘
- ä»Šæ—¥: {capital.get('northbound_data', {}).get('today', 0):.2f}äº¿
- æœ¬å‘¨: {capital.get('northbound_data', {}).get('week', 0):.2f}äº¿
- æœ¬æœˆ: {capital.get('northbound_data', {}).get('month', 0):.2f}äº¿
- è¶‹åŠ¿: {capital.get('northbound_trend', 'æœªçŸ¥')}

### å¸‚åœºæƒ…ç»ª
- æƒ…ç»ªå¾—åˆ†: {sentiment.get('sentiment_score', 50)}/100
- æƒ…ç»ªæ°´å¹³: {sentiment.get('sentiment_level', 'ä¸­æ€§')}
- æ¶¨åœå®¶æ•°: {sentiment.get('limit_up_count', 0)}
- è·Œåœå®¶æ•°: {sentiment.get('limit_down_count', 0)}

### åˆæ­¥åˆ†æç»“æœ
- æ¿å—è½®åŠ¨: {sector.get('sector_rotation', 'æœªçŸ¥')}
- ä¸»å¯¼ä¸»é¢˜: {', '.join(sector.get('leading_themes', []))}
- èµ„é‡‘å…±è¯†: {', '.join(capital.get('capital_consensus', []))}

## ğŸ¯ åˆ†æä»»åŠ¡

è¯·åŸºäºä»¥ä¸ŠçœŸå®æ•°æ®ï¼Œå®Œæˆæ·±åº¦åˆ†æï¼š

1. **éªŒè¯åˆæ­¥ç»“è®º**ï¼šä¸Šè¿°åˆæ­¥åˆ†ææ˜¯å¦åˆç†ï¼Ÿæœ‰æ— é—æ¼ï¼Ÿ

2. **ä¸»çº¿æ·±åº¦åˆ†æ**ï¼š
   - è¯†åˆ«1-3æ¡æœ€å¼ºæŠ•èµ„ä¸»çº¿
   - è¯´æ˜æ ¸å¿ƒé€»è¾‘å’Œæ”¯æ’‘å› ç´ 
   - è¯„ä¼°æŒç»­æ€§å’Œé£é™©

3. **æŠ•èµ„å»ºè®®**ï¼š
   - å…·ä½“æ¿å—å’Œé¾™å¤´è‚¡æ¨è
   - ä»“ä½é…ç½®å»ºè®®
   - é£æ§æªæ–½

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚
"""
        
        return prompt


# å…¨å±€å®ä¾‹
analysis_engine = MainlineAnalysisEngine()

