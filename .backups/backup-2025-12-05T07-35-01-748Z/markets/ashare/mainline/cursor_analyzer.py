"""
Aè‚¡ä¸»çº¿è¯†åˆ« - Cursoräº¤äº’åˆ†æå™¨

å°†çœŸå®æ•°æ®è½¬æ¢ä¸ºCursorå¯åˆ†æçš„Promptï¼Œ
ç”¨æˆ·å¯ä»¥åœ¨Cursor Chat/Composerä¸­è¿›è¡Œæ·±åº¦åˆ†æã€‚

å·¥ä½œæµç¨‹ï¼š
1. ä»AKShareè·å–çœŸå®æ•°æ®
2. æ•´ç†æ•°æ®ç”Ÿæˆåˆ†æPrompt
3. ç”¨æˆ·å¤åˆ¶Promptåˆ°Cursorè¿›è¡ŒAIåˆ†æ
4. æˆ–è€…ä¿å­˜Promptæ–‡ä»¶ï¼Œç”¨@fileå¼•ç”¨åˆ†æ
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import logging

from .real_data_fetcher import RealDataFetcher, real_data_fetcher, DataFetchResult

logger = logging.getLogger(__name__)


@dataclass
class AnalysisPrompt:
    """åˆ†æPrompt"""
    title: str
    prompt: str
    data_sources: List[str]
    data_time: datetime
    file_path: Optional[str] = None
    
    def to_dict(self) -> Dict:
        return {
            "title": self.title,
            "prompt": self.prompt,
            "data_sources": self.data_sources,
            "data_time": self.data_time.isoformat(),
            "file_path": self.file_path,
        }


class CursorAnalyzer:
    """
    Cursoräº¤äº’åˆ†æå™¨
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    1. è°ƒç”¨ generate_mainline_prompt() ç”Ÿæˆåˆ†æPrompt
    2. å¤åˆ¶Promptåˆ°Cursor Chatè¿›è¡Œåˆ†æ
    3. æˆ–è€…è°ƒç”¨ save_prompt_file() ä¿å­˜ä¸ºæ–‡ä»¶ï¼Œç”¨@fileå¼•ç”¨
    """
    
    def __init__(self, data_fetcher: Optional[RealDataFetcher] = None):
        self.fetcher = data_fetcher or real_data_fetcher
        self.prompt_dir = os.path.expanduser("~/.local/share/trquant/prompts")
        os.makedirs(self.prompt_dir, exist_ok=True)
    
    def generate_mainline_prompt(self) -> AnalysisPrompt:
        """
        ç”Ÿæˆä¸»çº¿è¯†åˆ«åˆ†æPrompt
        
        åŒ…å«çœŸå®çš„å¸‚åœºæ•°æ®ï¼Œä¾›Cursor AIåˆ†æ
        """
        # è·å–çœŸå®æ•°æ®
        logger.info("ğŸ“¡ è·å–çœŸå®å¸‚åœºæ•°æ®...")
        all_data = self.fetcher.fetch_all_data()
        
        # æ„å»ºæ•°æ®æ‘˜è¦
        data_summary = self._build_data_summary(all_data)
        
        # ç”ŸæˆPrompt
        prompt = f"""# Aè‚¡ä¸»çº¿è¯†åˆ«åˆ†æè¯·æ±‚

## ğŸ“… æ•°æ®æ—¶é—´
{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š çœŸå®å¸‚åœºæ•°æ®

{data_summary}

## ğŸ¯ åˆ†æä»»åŠ¡

è¯·åŸºäºä»¥ä¸ŠçœŸå®å¸‚åœºæ•°æ®ï¼Œå®Œæˆä»¥ä¸‹åˆ†æï¼š

### 1. å®è§‚ç¯å¢ƒåˆ¤æ–­
- å½“å‰æ”¿ç­–å‘¨æœŸï¼ˆå®½æ¾/ä¸­æ€§/æ”¶ç´§ï¼‰
- ç»æµå‘¨æœŸé˜¶æ®µï¼ˆå¤è‹/æ‰©å¼ /è¿‡çƒ­/è¡°é€€ï¼‰
- æµåŠ¨æ€§çŠ¶å†µ

### 2. èµ„é‡‘æµå‘åˆ†æ
- ä¸»åŠ›èµ„é‡‘æµå‘å“ªäº›æ¿å—ï¼Ÿ
- åŒ—å‘èµ„é‡‘åå¥½ä»€ä¹ˆæ–¹å‘ï¼Ÿ
- èµ„é‡‘å…±è¯†åœ¨å“ªé‡Œï¼Ÿ

### 3. ä¸»çº¿è¯†åˆ«
è¯†åˆ«1-3æ¡æœ€å¼ºæŠ•èµ„ä¸»çº¿ï¼Œæ¯æ¡ä¸»çº¿åŒ…å«ï¼š
- ä¸»çº¿åç§°å’Œæ ¸å¿ƒé€»è¾‘
- æ”¯æ’‘å› ç´ ï¼ˆæ”¿ç­–/èµ„é‡‘/äº§ä¸š/æŠ€æœ¯ï¼‰
- ç›¸å…³æ¿å—å’Œé¾™å¤´è‚¡
- é£é™©æç¤º

### 4. æŠ•èµ„å»ºè®®
- ä»“ä½é…ç½®å»ºè®®
- ä¹°å…¥/å–å‡ºæ—¶æœº
- é£æ§æªæ–½

## ğŸ“ è¾“å‡ºæ ¼å¼

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š
```json
{{
    "analysis_time": "åˆ†ææ—¶é—´",
    "data_sources": ["æ•°æ®æ¥æºåˆ—è¡¨"],
    "macro_environment": {{
        "policy_cycle": "æ”¿ç­–å‘¨æœŸ",
        "economic_cycle": "ç»æµå‘¨æœŸ",
        "liquidity": "æµåŠ¨æ€§çŠ¶å†µ"
    }},
    "capital_flow": {{
        "main_force_direction": ["ä¸»åŠ›æµå‘"],
        "northbound_preference": ["åŒ—å‘åå¥½"],
        "consensus": ["èµ„é‡‘å…±è¯†"]
    }},
    "mainlines": [
        {{
            "name": "ä¸»çº¿åç§°",
            "score": 0-100,
            "core_logic": "æ ¸å¿ƒé€»è¾‘",
            "supporting_factors": ["æ”¯æ’‘å› ç´ "],
            "sectors": ["ç›¸å…³æ¿å—"],
            "leading_stocks": ["é¾™å¤´è‚¡"],
            "risks": ["é£é™©"]
        }}
    ],
    "investment_advice": {{
        "position": "ä»“ä½å»ºè®®",
        "timing": "æ—¶æœºå»ºè®®",
        "risk_control": "é£æ§æªæ–½"
    }},
    "reasoning": "å®Œæ•´æ¨ç†è¿‡ç¨‹"
}}
```
"""
        
        # è®°å½•ä½¿ç”¨çš„æ•°æ®æº
        data_sources = [
            f"{key}: {result.source}" 
            for key, result in all_data.items() 
            if result.success
        ]
        
        return AnalysisPrompt(
            title="Aè‚¡ä¸»çº¿è¯†åˆ«åˆ†æ",
            prompt=prompt,
            data_sources=data_sources,
            data_time=datetime.now(),
        )
    
    def _build_data_summary(self, all_data: Dict[str, DataFetchResult]) -> str:
        """æ„å»ºæ•°æ®æ‘˜è¦"""
        sections = []
        
        # æ¿å—èµ„é‡‘æµå‘
        sector_flow = all_data.get("sector_flow")
        if sector_flow and sector_flow.success and sector_flow.data:
            sections.append("### ğŸ“ˆ æ¿å—èµ„é‡‘æµå‘ï¼ˆå®æ—¶ï¼‰")
            sections.append(f"æ•°æ®æ¥æº: {sector_flow.source}")
            sections.append("")
            sections.append("| æ¿å— | æ¶¨è·Œå¹… | ä¸»åŠ›å‡€æµå…¥(äº¿) | ä¸»åŠ›å‡€å æ¯” |")
            sections.append("|------|--------|----------------|------------|")
            for item in sector_flow.data[:15]:
                sections.append(
                    f"| {item['sector_name']} | "
                    f"{item['change_pct']:.2f}% | "
                    f"{item['main_net_inflow']:.2f} | "
                    f"{item['main_net_ratio']:.2f}% |"
                )
            sections.append("")
        
        # æ¦‚å¿µæ¿å—
        concept = all_data.get("concept_board")
        if concept and concept.success and concept.data:
            sections.append("### ğŸ”¥ çƒ­é—¨æ¦‚å¿µæ¿å—")
            sections.append(f"æ•°æ®æ¥æº: {concept.source}")
            sections.append("")
            sections.append("| æ¦‚å¿µ | æ¶¨è·Œå¹… | é¢†æ¶¨è‚¡ | é¢†æ¶¨å¹…åº¦ |")
            sections.append("|------|--------|--------|----------|")
            for item in concept.data[:15]:
                sections.append(
                    f"| {item['board_name']} | "
                    f"{item['change_pct']:.2f}% | "
                    f"{item['leader_stock']} | "
                    f"{item['leader_change']:.2f}% |"
                )
            sections.append("")
        
        # åŒ—å‘èµ„é‡‘
        north = all_data.get("northbound_flow")
        if north and north.success and north.data:
            sections.append("### ğŸ’° åŒ—å‘èµ„é‡‘æµå‘")
            sections.append(f"æ•°æ®æ¥æº: {north.source}")
            sections.append("")
            sections.append(f"- ä»Šæ—¥å‡€æµå…¥: {north.data.get('today_net', 0):.2f}äº¿")
            sections.append(f"- æœ¬å‘¨å‡€æµå…¥: {north.data.get('week_net', 0):.2f}äº¿")
            sections.append(f"- æœ¬æœˆå‡€æµå…¥: {north.data.get('month_net', 0):.2f}äº¿")
            sections.append("")
        
        # å¸‚åœºæƒ…ç»ª
        sentiment = all_data.get("market_sentiment")
        if sentiment and sentiment.success and sentiment.data:
            sections.append("### ğŸ­ å¸‚åœºæƒ…ç»ª")
            sections.append(f"æ•°æ®æ¥æº: {sentiment.source}")
            sections.append("")
            sections.append(f"- æ¶¨åœå®¶æ•°: {sentiment.data.get('up_limit_count', 0)}")
            sections.append(f"- è·Œåœå®¶æ•°: {sentiment.data.get('down_limit_count', 0)}")
            sections.append(f"- æƒ…ç»ªå¾—åˆ†: {sentiment.data.get('sentiment_score', 50)}/100")
            
            continuous = sentiment.data.get('continuous_limit', {})
            if continuous:
                sections.append(f"- è¿æ¿åˆ†å¸ƒ: {json.dumps(continuous, ensure_ascii=False)}")
            sections.append("")
        
        # é¾™è™æ¦œ
        dragon = all_data.get("dragon_tiger")
        if dragon and dragon.success and dragon.data:
            sections.append("### ğŸ‰ é¾™è™æ¦œ")
            sections.append(f"æ•°æ®æ¥æº: {dragon.source}")
            sections.append("")
            sections.append("| è‚¡ç¥¨ | ä¸Šæ¦œåŸå›  | å‡€ä¹°é¢(ä¸‡) |")
            sections.append("|------|----------|------------|")
            for item in dragon.data[:10]:
                sections.append(
                    f"| {item['name']} | "
                    f"{item['reason'][:15]} | "
                    f"{item['net_buy']:.0f} |"
                )
            sections.append("")
        
        # å®è§‚æ•°æ®
        macro = all_data.get("macro_data")
        if macro and macro.success and macro.data:
            sections.append("### ğŸ“‹ å®è§‚ç»æµæ•°æ®")
            sections.append(f"æ•°æ®æ¥æº: {macro.source}")
            sections.append("")
            if "pmi" in macro.data:
                sections.append(f"- PMI: {macro.data['pmi'].get('value', 'N/A')}")
            if "m2_growth" in macro.data:
                sections.append(f"- M2å¢é€Ÿ: {macro.data['m2_growth']}%")
            sections.append("")
        
        return "\n".join(sections)
    
    def save_prompt_file(self, prompt: AnalysisPrompt) -> str:
        """
        ä¿å­˜Promptåˆ°æ–‡ä»¶ï¼Œæ–¹ä¾¿åœ¨Cursorä¸­ç”¨@fileå¼•ç”¨
        """
        filename = f"mainline_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        filepath = os.path.join(self.prompt_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(prompt.prompt)
        
        prompt.file_path = filepath
        logger.info(f"âœ… Promptå·²ä¿å­˜: {filepath}")
        
        return filepath
    
    def get_cursor_instructions(self, prompt: AnalysisPrompt) -> str:
        """
        è·å–Cursorä½¿ç”¨è¯´æ˜
        """
        instructions = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ¤– Cursor AI åˆ†ææŒ‡å—                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                  â•‘
â•‘  ğŸ“Š æ•°æ®å·²å‡†å¤‡å®Œæ¯•ï¼                                              â•‘
â•‘                                                                  â•‘
â•‘  ä½¿ç”¨æ–¹æ³•ï¼š                                                       â•‘
â•‘                                                                  â•‘
â•‘  æ–¹æ³•1: ç›´æ¥å¤åˆ¶åˆ†æ                                              â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â•‘
â•‘  1. å¤åˆ¶ä¸‹æ–¹Prompt                                                â•‘
â•‘  2. æ‰“å¼€Cursor Chat (Cmd+L)                                       â•‘
â•‘  3. ç²˜è´´å¹¶å‘é€                                                    â•‘
â•‘  4. é€‰æ‹©æ¨¡å‹: Claude Opus 4 (æ¨è) æˆ– GPT-4o                      â•‘
â•‘                                                                  â•‘
â•‘  æ–¹æ³•2: æ–‡ä»¶å¼•ç”¨åˆ†æ                                              â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â•‘
â•‘  1. Promptå·²ä¿å­˜åˆ°: {prompt.file_path or '(æœªä¿å­˜)'}
â•‘  2. åœ¨Cursor Chatä¸­è¾“å…¥: @{os.path.basename(prompt.file_path) if prompt.file_path else 'file'}
â•‘  3. å‘é€åˆ†æè¯·æ±‚                                                  â•‘
â•‘                                                                  â•‘
â•‘  ğŸ“¡ æ•°æ®æ¥æº:                                                     â•‘
â•‘  {chr(10).join(['â•‘  - ' + s for s in prompt.data_sources[:5]])}
â•‘                                                                  â•‘
â•‘  â° æ•°æ®æ—¶é—´: {prompt.data_time.strftime('%Y-%m-%d %H:%M:%S')}
â•‘                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return instructions
    
    def run_analysis(self) -> Dict:
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        
        Returns:
            {
                "prompt": AnalysisPrompt,
                "file_path": str,
                "instructions": str,
                "data_status": Dict,
            }
        """
        # ç”ŸæˆPrompt
        prompt = self.generate_mainline_prompt()
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        file_path = self.save_prompt_file(prompt)
        
        # è·å–ä½¿ç”¨è¯´æ˜
        instructions = self.get_cursor_instructions(prompt)
        
        # æ•°æ®çŠ¶æ€
        data_status = self.fetcher.get_data_status()
        
        return {
            "prompt": prompt,
            "file_path": file_path,
            "instructions": instructions,
            "data_status": data_status,
        }


# å…¨å±€å®ä¾‹
cursor_analyzer = CursorAnalyzer()

