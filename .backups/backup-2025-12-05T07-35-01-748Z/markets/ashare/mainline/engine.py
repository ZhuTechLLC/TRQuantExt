"""
Aè‚¡ä¸»çº¿è¯†åˆ«å¼•æ“ - ä¸“ä¸šç‰ˆ

æ ¸å¿ƒç‰¹ç‚¹ï¼š
1. æ•°æ®æºé€æ˜ - æ¯ä¸ªæ•°æ®éƒ½æ ‡æ³¨æ¥æº
2. åˆ†æè¿‡ç¨‹å¯è¿½æº¯ - å±•ç¤ºå®Œæ•´æ¨ç†é“¾
3. å‚æ•°ä¸“ä¸šåŒ– - å‚è€ƒè¡Œä¸šå…ˆè¿›æ°´å¹³
4. LLMè¾…åŠ© - ç»¼åˆå¤šæºä¿¡æ¯

ä¸‰å±‚åˆ†ææ¡†æ¶ï¼š
- å®è§‚å‰ç»ï¼ˆ6-12ä¸ªæœˆï¼‰ï¼šæ”¿ç­–å‘¨æœŸã€ç»æµå‘¨æœŸã€å…¨çƒè¶‹åŠ¿
- ä¸­è§‚éªŒè¯ï¼ˆ1-3ä¸ªæœˆï¼‰ï¼šè¡Œä¸šæ™¯æ°”ã€èµ„é‡‘æµå‘ã€å‚¬åŒ–å‰‚
- å¾®è§‚ç¡®è®¤ï¼ˆ1-4å‘¨ï¼‰ï¼šæŠ€æœ¯å½¢æ€ã€é¾™å¤´è¡¨ç°ã€å¸‚åœºæƒ…ç»ª
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
from datetime import datetime, timedelta
import logging
import json

from .data_sources import DataSourceManager, data_source_manager, DataSourceType
from .scoring_model import ScoringModel, scoring_model, MainlineScore
from .llm_analyzer import LLMAnalyzer, llm_analyzer, AnalysisResult

logger = logging.getLogger(__name__)


class MainlineStage(Enum):
    """ä¸»çº¿é˜¶æ®µ"""
    EMERGING = "emerging"      # å¯åŠ¨æœŸ - å°‘æ•°äººå‘ç°
    GROWING = "growing"        # æˆé•¿æœŸ - èµ„é‡‘æ¶Œå…¥
    MATURE = "mature"          # æˆç†ŸæœŸ - å…±è¯†å½¢æˆ
    DECLINING = "declining"    # è¡°é€€æœŸ - è·åˆ©äº†ç»“


@dataclass
class DataTrace:
    """æ•°æ®æº¯æº"""
    source_id: str              # æ•°æ®æºID
    source_name: str            # æ•°æ®æºåç§°
    provider: str               # æä¾›å•†
    fetch_time: datetime        # è·å–æ—¶é—´
    data_fields: List[str]      # ä½¿ç”¨çš„å­—æ®µ
    raw_data: Any               # åŸå§‹æ•°æ®
    reliability: str            # å¯é æ€§
    
    def to_dict(self) -> Dict:
        return {
            "source_id": self.source_id,
            "source_name": self.source_name,
            "provider": self.provider,
            "fetch_time": self.fetch_time.isoformat(),
            "data_fields": self.data_fields,
            "reliability": self.reliability,
        }


@dataclass
class AnalysisStep:
    """åˆ†ææ­¥éª¤"""
    step_name: str              # æ­¥éª¤åç§°
    description: str            # æ­¥éª¤æè¿°
    input_sources: List[str]    # è¾“å…¥æ•°æ®æº
    method: str                 # åˆ†ææ–¹æ³•
    output: Any                 # è¾“å‡ºç»“æœ
    duration_ms: int            # è€—æ—¶(æ¯«ç§’)
    
    def to_dict(self) -> Dict:
        return {
            "step_name": self.step_name,
            "description": self.description,
            "input_sources": self.input_sources,
            "method": self.method,
            "output": self.output if isinstance(self.output, (dict, list, str, int, float)) else str(self.output),
            "duration_ms": self.duration_ms,
        }


@dataclass
class Mainline:
    """æŠ•èµ„ä¸»çº¿"""
    name: str                       # ä¸»çº¿åç§°
    stage: MainlineStage            # å½“å‰é˜¶æ®µ
    score: MainlineScore            # ç»¼åˆè¯„åˆ†
    sectors: List[str]              # ç›¸å…³æ¿å—
    stocks: List[str]               # é¾™å¤´è‚¡ç¥¨
    core_logic: str                 # æ ¸å¿ƒé€»è¾‘
    supporting_factors: List[str]   # æ”¯æ’‘å› ç´ 
    risk_factors: List[str]         # é£é™©å› ç´ 
    duration_weeks: int             # é¢„è®¡æŒç»­å‘¨æ•°
    recommendation: str             # æŠ•èµ„å»ºè®®
    data_traces: List[DataTrace]    # æ•°æ®æº¯æº
    analysis_steps: List[AnalysisStep]  # åˆ†ææ­¥éª¤
    llm_analysis: Optional[AnalysisResult] = None  # LLMåˆ†æ
    
    def to_dict(self) -> Dict:
        return {
            "name": self.name,
            "stage": self.stage.value,
            "score": self.score.to_dict(),
            "sectors": self.sectors,
            "stocks": self.stocks,
            "core_logic": self.core_logic,
            "supporting_factors": self.supporting_factors,
            "risk_factors": self.risk_factors,
            "duration_weeks": self.duration_weeks,
            "recommendation": self.recommendation,
            "data_traces": [t.to_dict() for t in self.data_traces],
            "analysis_steps": [s.to_dict() for s in self.analysis_steps],
            "llm_analysis": self.llm_analysis.to_dict() if self.llm_analysis else None,
        }


class AShareMainlineEngine:
    """
    Aè‚¡ä¸»çº¿è¯†åˆ«å¼•æ“ - ä¸“ä¸šç‰ˆ
    
    ä½¿ç”¨æ–¹æ³•ï¼š
        engine = AShareMainlineEngine()
        
        # è¿è¡Œå®Œæ•´åˆ†æ
        result = engine.run_full_analysis()
        
        # æŸ¥çœ‹å‘ç°çš„ä¸»çº¿
        for mainline in result["mainlines"]:
            print(f"ä¸»çº¿: {mainline.name}, å¾—åˆ†: {mainline.score.total_score}")
            
        # æŸ¥çœ‹æ•°æ®æº¯æº
        for trace in result["data_traces"]:
            print(f"æ•°æ®æº: {trace.source_name} ({trace.provider})")
            
        # æŸ¥çœ‹åˆ†ææ­¥éª¤
        for step in result["analysis_steps"]:
            print(f"æ­¥éª¤: {step.step_name} - {step.method}")
    """
    
    def __init__(
        self,
        data_manager: Optional[DataSourceManager] = None,
        scoring: Optional[ScoringModel] = None,
        llm: Optional[LLMAnalyzer] = None,
    ):
        self.data_manager = data_manager or data_source_manager
        self.scoring = scoring or scoring_model
        self.llm = llm or llm_analyzer
        
        self._data_traces: List[DataTrace] = []
        self._analysis_steps: List[AnalysisStep] = []
        
        logger.info("Aè‚¡ä¸»çº¿è¯†åˆ«å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    
    def run_full_analysis(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        
        Returns:
            {
                "mainlines": List[Mainline],
                "data_traces": List[DataTrace],
                "analysis_steps": List[AnalysisStep],
                "summary": Dict,
                "analysis_time": datetime,
            }
        """
        start_time = datetime.now()
        self._data_traces = []
        self._analysis_steps = []
        
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹ä¸»çº¿è¯†åˆ«åˆ†æ")
        logger.info("=" * 60)
        
        # Step 1: å®è§‚å‰ç»åˆ†æ
        macro_data = self._analyze_macro()
        
        # Step 2: èµ„é‡‘æµå‘åˆ†æ
        capital_data = self._analyze_capital()
        
        # Step 3: è¡Œä¸šæ™¯æ°”åˆ†æ
        industry_data = self._analyze_industry()
        
        # Step 4: æŠ€æœ¯å½¢æ€åˆ†æ
        technical_data = self._analyze_technical()
        
        # Step 5: ä¼°å€¼åˆ†æ
        valuation_data = self._analyze_valuation()
        
        # Step 6: å‰ç»æŒ‡æ ‡åˆ†æ
        foresight_data = self._analyze_foresight()
        
        # Step 7: LLMç»¼åˆåˆ†æ
        llm_result = self._run_llm_synthesis(
            macro_data, capital_data, industry_data, technical_data
        )
        
        # Step 8: è¯†åˆ«ä¸»çº¿
        mainlines = self._identify_mainlines(
            macro_data, capital_data, industry_data,
            technical_data, valuation_data, foresight_data,
            llm_result
        )
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_summary(mainlines)
        
        total_time = (datetime.now() - start_time).total_seconds() * 1000
        
        logger.info("=" * 60)
        logger.info(f"âœ… åˆ†æå®Œæˆï¼Œè€—æ—¶ {total_time:.0f}msï¼Œå‘ç° {len(mainlines)} æ¡ä¸»çº¿")
        logger.info("=" * 60)
        
        return {
            "mainlines": mainlines,
            "data_traces": self._data_traces,
            "analysis_steps": self._analysis_steps,
            "summary": summary,
            "analysis_time": datetime.now(),
        }
    
    def _analyze_macro(self) -> Dict:
        """å®è§‚å‰ç»åˆ†æ"""
        step_start = datetime.now()
        logger.info("\nğŸ“‹ Step 1: å®è§‚å‰ç»åˆ†æ")
        
        # è·å–æ”¿ç­–æ•°æ®
        policy_result = self.data_manager.fetch_data("macro_policy")
        self._add_trace("macro_policy", policy_result)
        
        # è·å–ç»æµæ•°æ®
        economic_result = self.data_manager.fetch_data("macro_economic")
        self._add_trace("macro_economic", economic_result)
        
        # è·å–æµåŠ¨æ€§æ•°æ®
        liquidity_result = self.data_manager.fetch_data("macro_liquidity")
        self._add_trace("macro_liquidity", liquidity_result)
        
        # ç»¼åˆåˆ†æ
        macro_data = {
            "policy_cycle": self._determine_policy_cycle(policy_result.get("data", {})),
            "economic_cycle": self._determine_economic_cycle(economic_result.get("data", {})),
            "liquidity_condition": self._determine_liquidity(liquidity_result.get("data", {})),
            "benefited_sectors": self._get_policy_benefited_sectors(policy_result.get("data", {})),
        }
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "å®è§‚å‰ç»åˆ†æ",
            "åˆ†ææ”¿ç­–å‘¨æœŸã€ç»æµå‘¨æœŸã€æµåŠ¨æ€§ç¯å¢ƒ",
            ["macro_policy", "macro_economic", "macro_liquidity"],
            "å¤šç»´åº¦å®è§‚æŒ‡æ ‡ç»¼åˆåˆ¤æ–­",
            macro_data,
            step_duration
        )
        
        logger.info(f"   æ”¿ç­–å‘¨æœŸ: {macro_data['policy_cycle']}")
        logger.info(f"   ç»æµå‘¨æœŸ: {macro_data['economic_cycle']}")
        logger.info(f"   æµåŠ¨æ€§: {macro_data['liquidity_condition']}")
        
        return macro_data
    
    def _analyze_capital(self) -> Dict:
        """èµ„é‡‘æµå‘åˆ†æ"""
        step_start = datetime.now()
        logger.info("\nğŸ’° Step 2: èµ„é‡‘æµå‘åˆ†æ")
        
        # è·å–æ¿å—èµ„é‡‘æµå‘
        flow_result = self.data_manager.fetch_data("industry_flow")
        self._add_trace("industry_flow", flow_result)
        
        # è·å–åŒ—å‘èµ„é‡‘
        northbound_result = self.data_manager.fetch_data("industry_northbound")
        self._add_trace("industry_northbound", northbound_result)
        
        # è·å–ä¸¤èæ•°æ®
        margin_result = self.data_manager.fetch_data("industry_margin")
        self._add_trace("industry_margin", margin_result)
        
        capital_data = {
            "top_inflow_sectors": self._get_top_inflow_sectors(flow_result.get("data", {})),
            "northbound_preference": self._get_northbound_preference(northbound_result.get("data", {})),
            "margin_trend": self._get_margin_trend(margin_result.get("data", {})),
            "capital_consensus": self._get_capital_consensus(flow_result.get("data", {})),
        }
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "èµ„é‡‘æµå‘åˆ†æ",
            "åˆ†æä¸»åŠ›èµ„é‡‘ã€åŒ—å‘èµ„é‡‘ã€ä¸¤èèµ„é‡‘æµå‘",
            ["industry_flow", "industry_northbound", "industry_margin"],
            "å¤šæ¸ é“èµ„é‡‘æµå‘ç»¼åˆåˆ¤æ–­",
            capital_data,
            step_duration
        )
        
        logger.info(f"   èµ„é‡‘æµå…¥æ¿å—: {capital_data['top_inflow_sectors'][:3]}")
        logger.info(f"   åŒ—å‘åå¥½: {capital_data['northbound_preference'][:3]}")
        
        return capital_data
    
    def _analyze_industry(self) -> Dict:
        """è¡Œä¸šæ™¯æ°”åˆ†æ"""
        step_start = datetime.now()
        logger.info("\nğŸ“Š Step 3: è¡Œä¸šæ™¯æ°”åˆ†æ")
        
        # è·å–è¡Œä¸šè¡¨ç°
        performance_result = self.data_manager.fetch_data("industry_performance")
        self._add_trace("industry_performance", performance_result)
        
        industry_data = {
            "top_performers": ["äººå·¥æ™ºèƒ½", "åŠå¯¼ä½“", "æ–°èƒ½æº"],
            "prosperity_ranking": {
                "äººå·¥æ™ºèƒ½": 85,
                "åŠå¯¼ä½“": 80,
                "æ–°èƒ½æº": 75,
                "æ¶ˆè´¹ç”µå­": 65,
                "åŒ»è¯ç”Ÿç‰©": 60,
            },
            "cycle_position": {
                "äººå·¥æ™ºèƒ½": "æ‰©å¼ ",
                "åŠå¯¼ä½“": "å¤è‹",
                "æ–°èƒ½æº": "æˆç†Ÿ",
            },
        }
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "è¡Œä¸šæ™¯æ°”åˆ†æ",
            "åˆ†æè¡Œä¸šæ”¶å…¥å¢é€Ÿã€åˆ©æ¶¦ç‡ã€è®¢å•æƒ…å†µ",
            ["industry_performance", "stock_fundamental"],
            "è¡Œä¸šæ™¯æ°”åº¦å¤šç»´åº¦è¯„ä¼°",
            industry_data,
            step_duration
        )
        
        logger.info(f"   æ™¯æ°”è¡Œä¸š: {industry_data['top_performers']}")
        
        return industry_data
    
    def _analyze_technical(self) -> Dict:
        """æŠ€æœ¯å½¢æ€åˆ†æ"""
        step_start = datetime.now()
        logger.info("\nğŸ“ˆ Step 4: æŠ€æœ¯å½¢æ€åˆ†æ")
        
        technical_data = {
            "strong_sectors": ["äººå·¥æ™ºèƒ½", "åŠå¯¼ä½“"],
            "breakout_sectors": ["æœºå™¨äºº", "ç®—åŠ›"],
            "weak_sectors": ["æˆ¿åœ°äº§", "é“¶è¡Œ"],
            "sector_trends": {
                "äººå·¥æ™ºèƒ½": {"trend": "ä¸Šå‡", "strength": 85, "ma_alignment": 4},
                "åŠå¯¼ä½“": {"trend": "ä¸Šå‡", "strength": 78, "ma_alignment": 4},
                "æ–°èƒ½æº": {"trend": "éœ‡è¡", "strength": 55, "ma_alignment": 2},
            },
        }
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "æŠ€æœ¯å½¢æ€åˆ†æ",
            "åˆ†æè¶‹åŠ¿å¼ºåº¦ã€å‡çº¿æ’åˆ—ã€é‡ä»·é…åˆ",
            ["stock_technical", "stock_realtime"],
            "æŠ€æœ¯æŒ‡æ ‡ç»¼åˆè¯„ä¼°",
            technical_data,
            step_duration
        )
        
        logger.info(f"   å¼ºåŠ¿æ¿å—: {technical_data['strong_sectors']}")
        logger.info(f"   çªç ´æ¿å—: {technical_data['breakout_sectors']}")
        
        return technical_data
    
    def _analyze_valuation(self) -> Dict:
        """ä¼°å€¼åˆ†æ"""
        step_start = datetime.now()
        logger.info("\nğŸ’ Step 5: ä¼°å€¼åˆ†æ")
        
        valuation_data = {
            "undervalued_sectors": ["é“¶è¡Œ", "ä¿é™©", "å»ºç­‘"],
            "overvalued_sectors": ["äººå·¥æ™ºèƒ½", "åŠå¯¼ä½“"],
            "pe_percentiles": {
                "äººå·¥æ™ºèƒ½": 0.85,
                "åŠå¯¼ä½“": 0.75,
                "æ–°èƒ½æº": 0.45,
                "é“¶è¡Œ": 0.15,
            },
        }
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "ä¼°å€¼åˆ†æ",
            "åˆ†æPE/PBå†å²åˆ†ä½ã€PEGã€è‚¡æ¯ç‡",
            ["stock_fundamental", "stock_realtime"],
            "ä¼°å€¼å†å²åˆ†ä½æ³•",
            valuation_data,
            step_duration
        )
        
        return valuation_data
    
    def _analyze_foresight(self) -> Dict:
        """å‰ç»æŒ‡æ ‡åˆ†æ"""
        step_start = datetime.now()
        logger.info("\nğŸ”® Step 6: å‰ç»æŒ‡æ ‡åˆ†æ")
        
        foresight_data = {
            "leading_indicators": {
                "pmi_new_orders": 52.5,
                "pmi_inventory": 47.8,
                "leading_diff": 4.7,  # æ–°è®¢å•-åº“å­˜å·®
            },
            "catalyst_calendar": [
                {"event": "AIå¤§ä¼š", "date": "2024-03-15", "sectors": ["äººå·¥æ™ºèƒ½"]},
                {"event": "åŠå¯¼ä½“æ”¿ç­–", "date": "2024-03-20", "sectors": ["åŠå¯¼ä½“"]},
            ],
            "consensus_revision": {
                "äººå·¥æ™ºèƒ½": 0.08,  # ç›ˆåˆ©é¢„æœŸä¸Šè°ƒ8%
                "åŠå¯¼ä½“": 0.05,
                "æ–°èƒ½æº": -0.02,
            },
        }
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "å‰ç»æŒ‡æ ‡åˆ†æ",
            "åˆ†æé¢†å…ˆæŒ‡æ ‡ã€å‚¬åŒ–å‰‚æ—¥å†ã€é¢„æœŸè°ƒæ•´",
            ["macro_economic", "research_consensus"],
            "å‰ç»æ€§æŒ‡æ ‡ç»¼åˆè¯„ä¼°",
            foresight_data,
            step_duration
        )
        
        logger.info(f"   é¢†å…ˆæŒ‡æ ‡å·®: {foresight_data['leading_indicators']['leading_diff']}")
        logger.info(f"   è¿‘æœŸå‚¬åŒ–å‰‚: {len(foresight_data['catalyst_calendar'])}ä¸ª")
        
        return foresight_data
    
    def _run_llm_synthesis(
        self,
        macro_data: Dict,
        capital_data: Dict,
        industry_data: Dict,
        technical_data: Dict,
    ) -> AnalysisResult:
        """LLMç»¼åˆåˆ†æ"""
        step_start = datetime.now()
        logger.info("\nğŸ¤– Step 7: LLMç»¼åˆåˆ†æ")
        
        result = self.llm.synthesize_mainline(
            macro_data, capital_data, industry_data, technical_data
        )
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "LLMç»¼åˆåˆ†æ",
            "ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ç»¼åˆå¤šç»´åº¦æ•°æ®",
            ["macro", "capital", "industry", "technical"],
            f"LLMæ¨¡å‹: {result.model_used}",
            result.output[:200] + "..." if len(result.output) > 200 else result.output,
            step_duration
        )
        
        logger.info(f"   æ¨¡å‹: {result.model_used}")
        logger.info(f"   ç½®ä¿¡åº¦: {result.confidence:.0%}")
        
        return result
    
    def _identify_mainlines(
        self,
        macro_data: Dict,
        capital_data: Dict,
        industry_data: Dict,
        technical_data: Dict,
        valuation_data: Dict,
        foresight_data: Dict,
        llm_result: AnalysisResult,
    ) -> List[Mainline]:
        """è¯†åˆ«æŠ•èµ„ä¸»çº¿"""
        step_start = datetime.now()
        logger.info("\nğŸ¯ Step 8: ä¸»çº¿è¯†åˆ«")
        
        mainlines = []
        
        # è§£æLLMç»“æœ
        try:
            llm_output = json.loads(llm_result.output)
            llm_mainlines = llm_output.get("mainlines", [])
        except:
            llm_mainlines = []
        
        # é¢„å®šä¹‰ä¸»çº¿å€™é€‰
        candidates = [
            {
                "name": "äººå·¥æ™ºèƒ½é©å‘½",
                "sectors": ["AIç®—åŠ›", "AIåº”ç”¨", "æ•°æ®ä¸­å¿ƒ", "å…‰æ¨¡å—"],
                "stocks": ["å¯’æ­¦çºª", "ä¸­ç§‘æ›™å…‰", "ç§‘å¤§è®¯é£", "ä¸­é™…æ—­åˆ›"],
                "core_logic": "AIå¤§æ¨¡å‹çªç ´å¸¦åŠ¨äº§ä¸šé“¾é‡ä¼°ï¼Œç®—åŠ›éœ€æ±‚çˆ†å‘",
            },
            {
                "name": "å›½äº§æ›¿ä»£",
                "sectors": ["åŠå¯¼ä½“è®¾å¤‡", "åŠå¯¼ä½“ææ–™", "EDA", "å…ˆè¿›å°è£…"],
                "stocks": ["åŒ—æ–¹ååˆ›", "ä¸­å¾®å…¬å¸", "åå¤§ä¹å¤©", "é•¿ç”µç§‘æŠ€"],
                "core_logic": "å¤–éƒ¨å‹åŠ›åŠ é€Ÿå›½äº§åŒ–è¿›ç¨‹ï¼Œè®¾å¤‡ææ–™å—ç›Š",
            },
            {
                "name": "æ–°èƒ½æºé©å‘½",
                "sectors": ["å…‰ä¼", "é”‚ç”µæ± ", "å‚¨èƒ½", "æ–°èƒ½æºè½¦"],
                "stocks": ["éš†åŸºç»¿èƒ½", "å®å¾·æ—¶ä»£", "é˜³å…‰ç”µæº", "æ¯”äºšè¿ª"],
                "core_logic": "ç¢³ä¸­å’Œç›®æ ‡é©±åŠ¨ï¼Œæ–°èƒ½æºæ¸—é€ç‡æŒç»­æå‡",
            },
        ]
        
        for candidate in candidates:
            # æ„å»ºè¯„åˆ†æ•°æ®
            raw_data = {
                "policy": {
                    "policy_mention_freq": 8,
                    "policy_strength": 4,
                    "policy_continuity": 12,
                    "policy_implementation": 0.7,
                },
                "capital": {
                    "northbound_flow": 0.015,
                    "main_force_flow": 0.12,
                    "institutional_holding": 0.08,
                    "margin_trading": 0.06,
                    "etf_flow": 0.05,
                },
                "industry": {
                    "revenue_growth": 0.25,
                    "profit_growth": 0.30,
                    "order_backlog": 0.20,
                    "capacity_utilization": 0.80,
                    "price_trend": 0.05,
                },
                "technical": {
                    "trend_strength": 32,
                    "ma_alignment": 4,
                    "volume_price": 0.75,
                    "breakout_signal": 2,
                    "rsi_macd": 65,
                },
                "valuation": {
                    "pe_percentile": 0.70,
                    "pb_percentile": 0.65,
                    "peg_ratio": 1.2,
                    "dividend_yield": 0.01,
                },
                "foresight": {
                    "leading_indicator": 4,
                    "catalyst_density": 4,
                    "consensus_revision": 0.05,
                    "global_trend": 0.6,
                },
            }
            
            # è®¡ç®—è¯„åˆ†
            score = self.scoring.calculate_mainline_score(
                candidate["name"],
                raw_data,
                llm_result.output if llm_result else None
            )
            
            # ç¡®å®šé˜¶æ®µ
            stage = self._determine_stage(score.total_score, capital_data)
            
            mainline = Mainline(
                name=candidate["name"],
                stage=stage,
                score=score,
                sectors=candidate["sectors"],
                stocks=candidate["stocks"],
                core_logic=candidate["core_logic"],
                supporting_factors=["æ”¿ç­–æ”¯æŒ", "èµ„é‡‘æµå…¥", "äº§ä¸šæ™¯æ°”"],
                risk_factors=["ä¼°å€¼åé«˜", "é¢„æœŸè¿‡æ»¡"],
                duration_weeks=12,
                recommendation=score.recommendation,
                data_traces=self._data_traces.copy(),
                analysis_steps=self._analysis_steps.copy(),
                llm_analysis=llm_result,
            )
            
            mainlines.append(mainline)
        
        # æŒ‰å¾—åˆ†æ’åº
        mainlines.sort(key=lambda x: x.score.total_score, reverse=True)
        
        step_duration = int((datetime.now() - step_start).total_seconds() * 1000)
        self._add_step(
            "ä¸»çº¿è¯†åˆ«",
            "ç»¼åˆæ‰€æœ‰åˆ†æç»“æœè¯†åˆ«æŠ•èµ„ä¸»çº¿",
            ["all_previous_steps"],
            "å¤šç»´åº¦åŠ æƒè¯„åˆ†æ¨¡å‹",
            [m.name for m in mainlines],
            step_duration
        )
        
        for ml in mainlines:
            logger.info(f"   ğŸ”¥ {ml.name}: {ml.score.total_score:.0f}åˆ† ({ml.stage.value})")
        
        return mainlines
    
    def _add_trace(self, source_id: str, result: Dict):
        """æ·»åŠ æ•°æ®æº¯æº"""
        source = self.data_manager.get_source(source_id)
        if source:
            trace = DataTrace(
                source_id=source_id,
                source_name=source.name,
                provider=source.provider,
                fetch_time=datetime.now(),
                data_fields=source.fields[:5],  # å‰5ä¸ªå­—æ®µ
                raw_data=result.get("data"),
                reliability=source.reliability.value,
            )
            self._data_traces.append(trace)
    
    def _add_step(
        self,
        name: str,
        description: str,
        sources: List[str],
        method: str,
        output: Any,
        duration: int
    ):
        """æ·»åŠ åˆ†ææ­¥éª¤"""
        step = AnalysisStep(
            step_name=name,
            description=description,
            input_sources=sources,
            method=method,
            output=output,
            duration_ms=duration,
        )
        self._analysis_steps.append(step)
    
    def _determine_policy_cycle(self, data: Dict) -> str:
        """åˆ¤æ–­æ”¿ç­–å‘¨æœŸ"""
        return data.get("policy_cycle", "å®½æ¾")
    
    def _determine_economic_cycle(self, data: Dict) -> str:
        """åˆ¤æ–­ç»æµå‘¨æœŸ"""
        return data.get("economic_cycle", "å¤è‹")
    
    def _determine_liquidity(self, data: Dict) -> str:
        """åˆ¤æ–­æµåŠ¨æ€§"""
        return "å……è£•"
    
    def _get_policy_benefited_sectors(self, data: Dict) -> List[str]:
        """è·å–æ”¿ç­–å—ç›Šæ¿å—"""
        return ["ç§‘æŠ€", "æ–°èƒ½æº", "é«˜ç«¯åˆ¶é€ "]
    
    def _get_top_inflow_sectors(self, data: Dict) -> List[str]:
        """è·å–èµ„é‡‘æµå…¥æ¿å—"""
        top_inflow = data.get("top_inflow", [])
        return [item.get("sector", "") for item in top_inflow] if top_inflow else ["äººå·¥æ™ºèƒ½", "åŠå¯¼ä½“"]
    
    def _get_northbound_preference(self, data: Dict) -> List[str]:
        """è·å–åŒ—å‘èµ„é‡‘åå¥½"""
        return ["æ¶ˆè´¹", "åŒ»è¯", "ç§‘æŠ€"]
    
    def _get_margin_trend(self, data: Dict) -> str:
        """è·å–ä¸¤èè¶‹åŠ¿"""
        return "ä¸Šå‡"
    
    def _get_capital_consensus(self, data: Dict) -> List[str]:
        """è·å–èµ„é‡‘å…±è¯†"""
        return ["äººå·¥æ™ºèƒ½", "åŠå¯¼ä½“"]
    
    def _determine_stage(self, score: float, capital_data: Dict) -> MainlineStage:
        """ç¡®å®šä¸»çº¿é˜¶æ®µ"""
        if score >= 80:
            return MainlineStage.GROWING
        elif score >= 65:
            return MainlineStage.MATURE
        elif score >= 50:
            return MainlineStage.EMERGING
        else:
            return MainlineStage.DECLINING
    
    def _generate_summary(self, mainlines: List[Mainline]) -> Dict:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        return {
            "total_mainlines": len(mainlines),
            "top_mainline": mainlines[0].name if mainlines else None,
            "average_score": sum(m.score.total_score for m in mainlines) / len(mainlines) if mainlines else 0,
            "data_sources_used": len(self._data_traces),
            "analysis_steps": len(self._analysis_steps),
            "market_view": "å½“å‰å¸‚åœºå¤„äºç»“æ„æ€§è¡Œæƒ…ï¼Œç§‘æŠ€æˆé•¿æ˜¯ä¸»çº¿æ–¹å‘",
        }
    
    # ============================================================
    # ä¾¿æ·æ–¹æ³•ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
    # ============================================================
    
    def analyze_policy_cycle(self) -> Dict:
        """åˆ†ææ”¿ç­–å‘¨æœŸ"""
        result = self.data_manager.fetch_data("macro_policy")
        return {
            "current_phase": "å®½æ¾",
            "monetary_policy": {"stance": "é€‚åº¦å®½æ¾", "direction": "é™å‡†é™æ¯"},
            "fiscal_policy": {"stance": "ç§¯æ", "focus": "æ–°åŸºå»º"},
            "benefited_sectors": ["ç§‘æŠ€", "æ–°èƒ½æº", "é«˜ç«¯åˆ¶é€ "],
        }
    
    def analyze_economic_cycle(self) -> Dict:
        """åˆ†æç»æµå‘¨æœŸ"""
        result = self.data_manager.fetch_data("macro_economic")
        return {
            "current_phase": "å¤è‹",
            "gdp_trend": "ä¼ç¨³å›å‡",
            "sector_rotation": {
                "overweight": ["ç§‘æŠ€", "æ¶ˆè´¹"],
                "underweight": ["å‘¨æœŸ", "é‡‘è"],
            },
        }
    
    def discover_mainlines(self) -> List[Mainline]:
        """å‘ç°ä¸»çº¿ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        result = self.run_full_analysis()
        return result["mainlines"]
