"""
Aè‚¡ä¸»çº¿è¯†åˆ« - çœŸå®æ•°æ®è·å–å™¨

è¿æ¥çœŸå®æ•°æ®æºè·å–å¸‚åœºæ•°æ®ï¼š
1. AKShare - å…è´¹å¼€æºé‡‘èæ•°æ®
2. MongoDB - æœ¬åœ°æ•°æ®ç¼“å­˜
3. æ–‡ä»¶ç³»ç»Ÿ - è°ƒç ”æŠ¥å‘Šå­˜å‚¨

æ•°æ®ç±»å‹ï¼š
- æ¿å—è¡Œæƒ…æ•°æ®
- èµ„é‡‘æµå‘æ•°æ®
- åŒ—å‘èµ„é‡‘æ•°æ®
- å¸‚åœºæƒ…ç»ªæ•°æ®
- å®è§‚ç»æµæ•°æ®
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
import json
import os

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥akshare
try:
    import akshare as ak
    AKSHARE_AVAILABLE = True
    logger.info("âœ… AKShare å¯ç”¨")
except ImportError:
    AKSHARE_AVAILABLE = False
    logger.warning("âš ï¸ AKShare æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç¼“å­˜æ•°æ®")

# å°è¯•å¯¼å…¥pymongo
try:
    from pymongo import MongoClient
    MONGODB_AVAILABLE = True
except ImportError:
    MONGODB_AVAILABLE = False
    logger.warning("âš ï¸ PyMongo æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ–‡ä»¶ç¼“å­˜")

# å°è¯•å¯¼å…¥pandas
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False


@dataclass
class DataFetchResult:
    """æ•°æ®è·å–ç»“æœ"""
    success: bool
    data: Any
    source: str                  # æ•°æ®æ¥æº: akshare, mongodb, cache, mock
    fetch_time: datetime
    cache_time: Optional[datetime] = None
    error: Optional[str] = None
    
    def to_dict(self) -> Dict:
        return {
            "success": self.success,
            "source": self.source,
            "fetch_time": self.fetch_time.isoformat(),
            "cache_time": self.cache_time.isoformat() if self.cache_time else None,
            "error": self.error,
            "data_preview": str(self.data)[:200] if self.data else None,
        }


class RealDataFetcher:
    """
    çœŸå®æ•°æ®è·å–å™¨
    
    æ•°æ®è·å–ä¼˜å…ˆçº§ï¼š
    1. AKShare APIï¼ˆå®æ—¶æ•°æ®ï¼‰
    2. MongoDBç¼“å­˜ï¼ˆè¿‘æœŸæ•°æ®ï¼‰
    3. æ–‡ä»¶ç¼“å­˜ï¼ˆå†å²æ•°æ®ï¼‰
    """
    
    def __init__(self, mongo_uri: str = "mongodb://localhost:27017"):
        self.mongo_uri = mongo_uri
        self.db = None
        self.cache_dir = os.path.expanduser("~/.local/share/trquant/cache")
        os.makedirs(self.cache_dir, exist_ok=True)
        
        self._init_mongodb()
    
    def _init_mongodb(self):
        """åˆå§‹åŒ–MongoDBè¿æ¥"""
        if MONGODB_AVAILABLE:
            try:
                client = MongoClient(self.mongo_uri, serverSelectionTimeoutMS=2000)
                client.server_info()  # æµ‹è¯•è¿æ¥
                self.db = client.jqquant
                logger.info("âœ… MongoDB è¿æ¥æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ MongoDB è¿æ¥å¤±è´¥: {e}")
                self.db = None
    
    # ================================================================
    # æ¿å—æ•°æ®ï¼ˆä½¿ç”¨åŒèŠ±é¡ºæ•°æ®æºï¼Œé¿å…ä¸œæ–¹è´¢å¯Œåçˆ¬è™«ï¼‰
    # ================================================================
    
    def fetch_sector_flow(self, timeout: int = 15) -> DataFetchResult:
        """
        è·å–æ¿å—èµ„é‡‘æµå‘æ•°æ®
        
        æ•°æ®æº: åŒèŠ±é¡º -> AKShare (stock_fund_flow_industry)
        å­—æ®µ: è¡Œä¸šåç§°ã€æ¶¨è·Œå¹…ã€èµ„é‡‘æµå…¥æµå‡ºã€å‡€é¢ç­‰
        """
        try:
            if AKSHARE_AVAILABLE:
                import socket
                socket.setdefaulttimeout(timeout)
                
                # ä½¿ç”¨åŒèŠ±é¡ºè¡Œä¸šèµ„é‡‘æµå‘APIï¼ˆæ›´ç¨³å®šï¼‰
                df = ak.stock_fund_flow_industry(symbol="å³æ—¶")
                
                if df is not None and not df.empty:
                    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    data = []
                    for _, row in df.head(30).iterrows():
                        # å‡€é¢å•ä½æ˜¯äº¿å…ƒ
                        net_inflow = float(row.get("å‡€é¢", 0))
                        inflow = float(row.get("æµå…¥èµ„é‡‘", 0))
                        outflow = float(row.get("æµå‡ºèµ„é‡‘", 0))
                        
                        data.append({
                            "sector_name": row.get("è¡Œä¸š", ""),
                            "change_pct": float(row.get("è¡Œä¸š-æ¶¨è·Œå¹…", 0)),
                            "main_net_inflow": net_inflow,
                            "main_net_ratio": (net_inflow / inflow * 100) if inflow > 0 else 0,
                            "inflow": inflow,
                            "outflow": outflow,
                            "leader_stock": row.get("é¢†æ¶¨è‚¡", ""),
                            "leader_change": float(row.get("é¢†æ¶¨è‚¡-æ¶¨è·Œå¹…", 0)),
                        })
                    
                    # ç¼“å­˜åˆ°MongoDB
                    self._cache_to_mongo("sector_flow", data)
                    
                    return DataFetchResult(
                        success=True,
                        data=data,
                        source="akshare(åŒèŠ±é¡º)",
                        fetch_time=datetime.now(),
                    )
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached = self._get_from_cache("sector_flow")
            if cached:
                return cached
            
            # ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆç½‘ç»œä¸å¯ç”¨æ—¶ï¼‰
            return self._get_sample_sector_flow()
            
        except Exception as e:
            logger.warning(f"è·å–æ¿å—èµ„é‡‘æµå‘å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜...")
            cached = self._get_from_cache("sector_flow")
            if cached:
                return cached
            # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
            return self._get_sample_sector_flow()
    
    def _get_sample_sector_flow(self) -> DataFetchResult:
        """è·å–ç¤ºä¾‹æ¿å—æ•°æ®ï¼ˆç½‘ç»œä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        sample_data = [
            {"sector_name": "äººå·¥æ™ºèƒ½", "change_pct": 3.25, "main_net_inflow": 45.6, "main_net_ratio": 12.5, "super_large_inflow": 25.3, "large_inflow": 20.3},
            {"sector_name": "åŠå¯¼ä½“", "change_pct": 2.88, "main_net_inflow": 38.2, "main_net_ratio": 10.8, "super_large_inflow": 20.1, "large_inflow": 18.1},
            {"sector_name": "å…‰æ¨¡å—", "change_pct": 4.52, "main_net_inflow": 28.5, "main_net_ratio": 15.2, "super_large_inflow": 15.8, "large_inflow": 12.7},
            {"sector_name": "ç®—åŠ›", "change_pct": 3.15, "main_net_inflow": 22.3, "main_net_ratio": 11.3, "super_large_inflow": 12.5, "large_inflow": 9.8},
            {"sector_name": "æ–°èƒ½æº", "change_pct": 1.25, "main_net_inflow": 15.8, "main_net_ratio": 5.6, "super_large_inflow": 8.5, "large_inflow": 7.3},
            {"sector_name": "æ¶ˆè´¹ç”µå­", "change_pct": 1.88, "main_net_inflow": 12.5, "main_net_ratio": 6.8, "super_large_inflow": 7.2, "large_inflow": 5.3},
            {"sector_name": "åŒ»è¯ç”Ÿç‰©", "change_pct": 0.95, "main_net_inflow": 8.6, "main_net_ratio": 3.2, "super_large_inflow": 4.8, "large_inflow": 3.8},
            {"sector_name": "æ±½è½¦", "change_pct": 1.55, "main_net_inflow": 10.2, "main_net_ratio": 4.5, "super_large_inflow": 5.5, "large_inflow": 4.7},
            {"sector_name": "é“¶è¡Œ", "change_pct": -0.35, "main_net_inflow": -5.8, "main_net_ratio": -1.2, "super_large_inflow": -3.2, "large_inflow": -2.6},
            {"sector_name": "æˆ¿åœ°äº§", "change_pct": -1.25, "main_net_inflow": -12.5, "main_net_ratio": -4.5, "super_large_inflow": -7.2, "large_inflow": -5.3},
        ]
        return DataFetchResult(
            success=True,
            data=sample_data,
            source="sample_dataï¼ˆç½‘ç»œä¸å¯ç”¨ï¼‰",
            fetch_time=datetime.now(),
            error="ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®",
        )
    
    def fetch_concept_board(self) -> DataFetchResult:
        """
        è·å–æ¦‚å¿µæ¿å—è¡Œæƒ…
        
        æ•°æ®æº: åŒèŠ±é¡º -> AKShare (stock_fund_flow_concept)
        """
        try:
            if AKSHARE_AVAILABLE:
                import socket
                socket.setdefaulttimeout(20)
                
                # ä½¿ç”¨åŒèŠ±é¡ºæ¦‚å¿µèµ„é‡‘æµå‘APIï¼ˆæ›´ç¨³å®šï¼‰
                df = ak.stock_fund_flow_concept(symbol="å³æ—¶")
                
                if df is not None and not df.empty:
                    data = []
                    for _, row in df.head(50).iterrows():
                        net_inflow = float(row.get("å‡€é¢", 0))
                        
                        data.append({
                            "board_name": row.get("è¡Œä¸š", ""),  # æ¦‚å¿µåç§°
                            "change_pct": float(row.get("è¡Œä¸š-æ¶¨è·Œå¹…", 0)),
                            "net_inflow": net_inflow,
                            "inflow": float(row.get("æµå…¥èµ„é‡‘", 0)),
                            "outflow": float(row.get("æµå‡ºèµ„é‡‘", 0)),
                            "company_count": int(row.get("å…¬å¸å®¶æ•°", 0)),
                            "leader_stock": row.get("é¢†æ¶¨è‚¡", ""),
                            "leader_change": float(row.get("é¢†æ¶¨è‚¡-æ¶¨è·Œå¹…", 0)),
                        })
                    
                    self._cache_to_mongo("concept_board", data)
                    
                    return DataFetchResult(
                        success=True,
                        data=data,
                        source="akshare(åŒèŠ±é¡º)",
                        fetch_time=datetime.now(),
                    )
            
            cached = self._get_from_cache("concept_board")
            if cached:
                return cached
            
            return self._get_sample_concept_board()
            
        except Exception as e:
            logger.warning(f"è·å–æ¦‚å¿µæ¿å—å¤±è´¥: {e}")
            cached = self._get_from_cache("concept_board")
            return cached if cached else self._get_sample_concept_board()
    
    def _get_sample_concept_board(self) -> DataFetchResult:
        """è·å–ç¤ºä¾‹æ¦‚å¿µæ¿å—æ•°æ®"""
        sample_data = [
            {"board_name": "ChatGPTæ¦‚å¿µ", "change_pct": 4.25, "total_mv": 15000, "turnover_rate": 5.2, "up_count": 45, "down_count": 5, "leader_stock": "ç§‘å¤§è®¯é£", "leader_change": 8.5},
            {"board_name": "ç®—åŠ›", "change_pct": 3.88, "total_mv": 12000, "turnover_rate": 4.8, "up_count": 38, "down_count": 8, "leader_stock": "ä¸­ç§‘æ›™å…‰", "leader_change": 7.2},
            {"board_name": "å…‰æ¨¡å—", "change_pct": 5.15, "total_mv": 3500, "turnover_rate": 8.5, "up_count": 18, "down_count": 2, "leader_stock": "ä¸­é™…æ—­åˆ›", "leader_change": 10.0},
            {"board_name": "åŠå¯¼ä½“è®¾å¤‡", "change_pct": 2.95, "total_mv": 8000, "turnover_rate": 3.8, "up_count": 28, "down_count": 6, "leader_stock": "åŒ—æ–¹ååˆ›", "leader_change": 5.5},
            {"board_name": "æœºå™¨äºº", "change_pct": 3.45, "total_mv": 5500, "turnover_rate": 6.2, "up_count": 32, "down_count": 4, "leader_stock": "æ±‡å·æŠ€æœ¯", "leader_change": 6.8},
        ]
        return DataFetchResult(
            success=True,
            data=sample_data,
            source="sample_dataï¼ˆç½‘ç»œä¸å¯ç”¨ï¼‰",
            fetch_time=datetime.now(),
        )
    
    # ================================================================
    # åŒ—å‘èµ„é‡‘
    # ================================================================
    
    def fetch_northbound_flow(self) -> DataFetchResult:
        """
        è·å–åŒ—å‘èµ„é‡‘æµå‘
        
        æ•°æ®æº: ä¸œæ–¹è´¢å¯Œ -> AKShare
        API: stock_hsgt_fund_flow_summary_em (æ–°ç‰ˆAPI)
        """
        try:
            if AKSHARE_AVAILABLE:
                import socket
                socket.setdefaulttimeout(15)
                
                # ä½¿ç”¨æ–°ç‰ˆAPI: stock_hsgt_fund_flow_summary_em
                df = ak.stock_hsgt_fund_flow_summary_em()
                
                if df is not None and not df.empty:
                    # ç­›é€‰åŒ—å‘èµ„é‡‘ï¼ˆæ²ªè‚¡é€š+æ·±è‚¡é€šï¼‰
                    north_df = df[df["èµ„é‡‘æ–¹å‘"] == "åŒ—å‘"]
                    
                    # è®¡ç®—ä»Šæ—¥å‡€æµå…¥
                    today_net = 0
                    for _, row in north_df.iterrows():
                        try:
                            # èµ„é‡‘å‡€æµå…¥åˆ—
                            net = float(row.get("èµ„é‡‘å‡€æµå…¥", 0))
                            today_net += net
                        except:
                            pass
                    
                    # è½¬æ¢ä¸ºäº¿å…ƒ
                    today_net = today_net / 1e8 if today_net > 1e6 else today_net
                    
                    data = {
                        "today_net": today_net,
                        "week_net": today_net * 5,  # ä¼°ç®—å€¼
                        "month_net": today_net * 20,  # ä¼°ç®—å€¼
                        "details": [
                            {
                                "æ¿å—": row.get("æ¿å—", ""),
                                "æˆäº¤å‡€ä¹°é¢": float(row.get("æˆäº¤å‡€ä¹°é¢", 0)) / 1e8,
                                "èµ„é‡‘å‡€æµå…¥": float(row.get("èµ„é‡‘å‡€æµå…¥", 0)) / 1e8,
                            }
                            for _, row in north_df.iterrows()
                        ],
                        "fetch_date": datetime.now().strftime("%Y-%m-%d"),
                    }
                    
                    self._cache_to_mongo("northbound_flow", data)
                    
                    return DataFetchResult(
                        success=True,
                        data=data,
                        source="akshare",
                        fetch_time=datetime.now(),
                    )
            
            cached = self._get_from_cache("northbound_flow")
            if cached:
                return cached
            
            return self._get_sample_northbound()
            
        except Exception as e:
            logger.warning(f"è·å–åŒ—å‘èµ„é‡‘å¤±è´¥: {e}")
            cached = self._get_from_cache("northbound_flow")
            return cached if cached else self._get_sample_northbound()
    
    def _get_sample_northbound(self) -> DataFetchResult:
        """è·å–ç¤ºä¾‹åŒ—å‘èµ„é‡‘æ•°æ®"""
        return DataFetchResult(
            success=True,
            data={
                "today_net": 45.8,
                "week_net": 125.6,
                "month_net": 380.2,
                "history": [
                    {"date": "2024-01-25", "net_flow": 45.8},
                    {"date": "2024-01-24", "net_flow": 32.5},
                    {"date": "2024-01-23", "net_flow": -15.2},
                ]
            },
            source="sample_dataï¼ˆç½‘ç»œä¸å¯ç”¨ï¼‰",
            fetch_time=datetime.now(),
        )
    
    # ================================================================
    # å¸‚åœºæƒ…ç»ª
    # ================================================================
    
    def fetch_market_sentiment(self) -> DataFetchResult:
        """
        è·å–å¸‚åœºæƒ…ç»ªæ•°æ®
        
        åŒ…å«ï¼šæ¶¨è·Œå®¶æ•°ã€æ¶¨åœè·Œåœã€è¿æ¿æ•°ç­‰
        """
        try:
            if AKSHARE_AVAILABLE:
                import socket
                socket.setdefaulttimeout(10)
                
                df_zt = ak.stock_zt_pool_em(date=datetime.now().strftime("%Y%m%d"))
                
                try:
                    df_dt = ak.stock_zt_pool_dtgc_em(date=datetime.now().strftime("%Y%m%d"))
                    down_limit_count = len(df_dt) if df_dt is not None else 0
                except:
                    down_limit_count = 0
                
                up_limit_count = len(df_zt) if df_zt is not None else 0
                
                continuous_limit = {}
                if df_zt is not None and not df_zt.empty and "è¿æ¿æ•°" in df_zt.columns:
                    for _, row in df_zt.iterrows():
                        lb = int(row.get("è¿æ¿æ•°", 1))
                        continuous_limit[lb] = continuous_limit.get(lb, 0) + 1
                
                data = {
                    "up_limit_count": up_limit_count,
                    "down_limit_count": down_limit_count,
                    "continuous_limit": continuous_limit,
                    "sentiment_score": min(100, max(0, 50 + (up_limit_count - down_limit_count) * 2)),
                    "fetch_date": datetime.now().strftime("%Y-%m-%d"),
                }
                
                self._cache_to_mongo("market_sentiment", data)
                
                return DataFetchResult(
                    success=True,
                    data=data,
                    source="akshare",
                    fetch_time=datetime.now(),
                )
            
            cached = self._get_from_cache("market_sentiment")
            if cached:
                return cached
            
            return self._get_sample_sentiment()
            
        except Exception as e:
            logger.warning(f"è·å–å¸‚åœºæƒ…ç»ªå¤±è´¥: {e}")
            cached = self._get_from_cache("market_sentiment")
            return cached if cached else self._get_sample_sentiment()
    
    def _get_sample_sentiment(self) -> DataFetchResult:
        """è·å–ç¤ºä¾‹å¸‚åœºæƒ…ç»ªæ•°æ®"""
        return DataFetchResult(
            success=True,
            data={
                "up_limit_count": 68,
                "down_limit_count": 12,
                "continuous_limit": {1: 45, 2: 15, 3: 5, 4: 2, 5: 1},
                "sentiment_score": 72,
                "fetch_date": datetime.now().strftime("%Y-%m-%d"),
            },
            source="sample_dataï¼ˆç½‘ç»œä¸å¯ç”¨ï¼‰",
            fetch_time=datetime.now(),
        )
    
    # ================================================================
    # å®è§‚æ•°æ®
    # ================================================================
    
    def fetch_macro_data(self) -> DataFetchResult:
        """
        è·å–å®è§‚ç»æµæ•°æ®
        
        åŒ…å«ï¼šPMIã€CPIã€ç¤¾èç­‰
        """
        try:
            data = {}
            
            if AKSHARE_AVAILABLE:
                # PMIæ•°æ®
                try:
                    df_pmi = ak.macro_china_pmi_yearly()
                    if df_pmi is not None and not df_pmi.empty:
                        latest_pmi = df_pmi.iloc[-1]
                        data["pmi"] = {
                            "value": float(latest_pmi.get("åˆ¶é€ ä¸š-Loss", latest_pmi.iloc[-1])),
                            "date": str(latest_pmi.name if hasattr(latest_pmi, 'name') else ""),
                        }
                except Exception as e:
                    logger.warning(f"è·å–PMIå¤±è´¥: {e}")
                
                # å°è¯•è·å–å…¶ä»–å®è§‚æ•°æ®
                try:
                    # M2æ•°æ®
                    df_m2 = ak.macro_china_money_supply()
                    if df_m2 is not None and not df_m2.empty:
                        latest = df_m2.iloc[-1]
                        data["m2_growth"] = float(latest.get("M2-åŒæ¯”å¢é•¿", 0))
                except:
                    pass
                
                if data:
                    self._cache_to_mongo("macro_data", data)
                    return DataFetchResult(
                        success=True,
                        data=data,
                        source="akshare",
                        fetch_time=datetime.now(),
                    )
            
            cached = self._get_from_cache("macro_data")
            if cached:
                return cached
                
            return DataFetchResult(
                success=False, data=None, source="none",
                fetch_time=datetime.now(), error="æ— æ³•è·å–æ•°æ®"
            )
            
        except Exception as e:
            logger.error(f"è·å–å®è§‚æ•°æ®å¤±è´¥: {e}")
            cached = self._get_from_cache("macro_data")
            return cached if cached else DataFetchResult(
                success=False, data=None, source="error",
                fetch_time=datetime.now(), error=str(e)
            )
    
    # ================================================================
    # é¾™è™æ¦œ
    # ================================================================
    
    def fetch_dragon_tiger(self) -> DataFetchResult:
        """
        è·å–é¾™è™æ¦œæ•°æ®
        """
        try:
            if AKSHARE_AVAILABLE:
                df = ak.stock_lhb_detail_em(
                    start_date=datetime.now().strftime("%Y%m%d"),
                    end_date=datetime.now().strftime("%Y%m%d")
                )
                
                if df is not None and not df.empty:
                    data = []
                    for _, row in df.head(20).iterrows():
                        # å®‰å…¨è·å–å€¼ï¼Œé˜²æ­¢Noneç±»å‹é”™è¯¯
                        net_buy = row.get("å‡€ä¹°é¢", 0)
                        try:
                            net_buy_val = float(net_buy) / 1e4 if net_buy is not None else 0.0
                        except (TypeError, ValueError):
                            net_buy_val = 0.0
                        data.append({
                            "code": str(row.get("ä»£ç ", "") or ""),
                            "name": str(row.get("åç§°", "") or ""),
                            "reason": str(row.get("ä¸Šæ¦œåŸå› ", "") or ""),
                            "net_buy": net_buy_val,  # ä¸‡å…ƒ
                        })
                    
                    self._cache_to_mongo("dragon_tiger", data)
                    
                    return DataFetchResult(
                        success=True,
                        data=data,
                        source="akshare",
                        fetch_time=datetime.now(),
                    )
            
            cached = self._get_from_cache("dragon_tiger")
            if cached:
                return cached
                
            return DataFetchResult(
                success=False, data=None, source="none",
                fetch_time=datetime.now(), error="æ— æ³•è·å–æ•°æ®"
            )
            
        except Exception as e:
            logger.error(f"è·å–é¾™è™æ¦œå¤±è´¥: {e}")
            cached = self._get_from_cache("dragon_tiger")
            return cached if cached else DataFetchResult(
                success=False, data=None, source="error",
                fetch_time=datetime.now(), error=str(e)
            )
    
    # ================================================================
    # ç»¼åˆæ•°æ®è·å–
    # ================================================================
    
    def fetch_all_data(self) -> Dict[str, DataFetchResult]:
        """
        è·å–æ‰€æœ‰æ•°æ®æºçš„æ•°æ®
        """
        results = {}
        
        logger.info("ğŸ“¡ å¼€å§‹è·å–çœŸå®å¸‚åœºæ•°æ®...")
        
        # æ¿å—èµ„é‡‘æµå‘
        logger.info("  â†’ è·å–æ¿å—èµ„é‡‘æµå‘...")
        results["sector_flow"] = self.fetch_sector_flow()
        
        # æ¦‚å¿µæ¿å—
        logger.info("  â†’ è·å–æ¦‚å¿µæ¿å—è¡Œæƒ…...")
        results["concept_board"] = self.fetch_concept_board()
        
        # åŒ—å‘èµ„é‡‘
        logger.info("  â†’ è·å–åŒ—å‘èµ„é‡‘æµå‘...")
        results["northbound_flow"] = self.fetch_northbound_flow()
        
        # å¸‚åœºæƒ…ç»ª
        logger.info("  â†’ è·å–å¸‚åœºæƒ…ç»ªæ•°æ®...")
        results["market_sentiment"] = self.fetch_market_sentiment()
        
        # å®è§‚æ•°æ®
        logger.info("  â†’ è·å–å®è§‚ç»æµæ•°æ®...")
        results["macro_data"] = self.fetch_macro_data()
        
        # é¾™è™æ¦œ
        logger.info("  â†’ è·å–é¾™è™æ¦œæ•°æ®...")
        results["dragon_tiger"] = self.fetch_dragon_tiger()
        
        # ç»Ÿè®¡
        success_count = sum(1 for r in results.values() if r.success)
        logger.info(f"âœ… æ•°æ®è·å–å®Œæˆ: {success_count}/{len(results)} æˆåŠŸ")
        
        return results
    
    # ================================================================
    # ç¼“å­˜ç®¡ç†
    # ================================================================
    
    def _cache_to_mongo(self, key: str, data: Any):
        """ç¼“å­˜æ•°æ®åˆ°MongoDB"""
        if self.db is not None:
            try:
                # ç¡®ä¿æ•°æ®å¯ä»¥è¢«MongoDBå­˜å‚¨ï¼ˆå°†inté”®è½¬ä¸ºstrï¼‰
                safe_data = self._make_mongo_safe(data)
                self.db.cache.update_one(
                    {"key": key},
                    {
                        "$set": {
                            "data": safe_data,
                            "updated_at": datetime.now(),
                        }
                    },
                    upsert=True
                )
            except Exception as e:
                logger.warning(f"MongoDBç¼“å­˜å¤±è´¥: {e}")
        
        # åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶
        self._cache_to_file(key, data)
    
    def _make_mongo_safe(self, data: Any) -> Any:
        """ç¡®ä¿æ•°æ®å¯ä»¥è¢«MongoDBå­˜å‚¨"""
        if isinstance(data, dict):
            return {str(k): self._make_mongo_safe(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._make_mongo_safe(item) for item in data]
        else:
            return data
    
    def _cache_to_file(self, key: str, data: Any):
        """ç¼“å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            cache_file = os.path.join(self.cache_dir, f"{key}.json")
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "data": data,
                    "updated_at": datetime.now().isoformat(),
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
    
    def _get_from_cache(self, key: str) -> Optional[DataFetchResult]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        # å…ˆå°è¯•MongoDB
        if self.db is not None:
            try:
                doc = self.db.cache.find_one({"key": key})
                if doc:
                    return DataFetchResult(
                        success=True,
                        data=doc["data"],
                        source="mongodb",
                        fetch_time=datetime.now(),
                        cache_time=doc.get("updated_at"),
                    )
            except:
                pass
        
        # å†å°è¯•æ–‡ä»¶ç¼“å­˜
        try:
            cache_file = os.path.join(self.cache_dir, f"{key}.json")
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached = json.load(f)
                    return DataFetchResult(
                        success=True,
                        data=cached["data"],
                        source="file_cache",
                        fetch_time=datetime.now(),
                        cache_time=datetime.fromisoformat(cached["updated_at"]),
                    )
        except:
            pass
        
        return None
    
    def get_data_status(self) -> Dict:
        """è·å–æ•°æ®æºçŠ¶æ€"""
        return {
            "akshare_available": AKSHARE_AVAILABLE,
            "akshare_version": ak.__version__ if AKSHARE_AVAILABLE else None,
            "mongodb_available": self.db is not None,
            "mongodb_uri": self.mongo_uri if self.db is not None else None,
            "cache_dir": self.cache_dir,
            "cache_files": os.listdir(self.cache_dir) if os.path.exists(self.cache_dir) else [],
        }
    
    def test_all_connections(self) -> Dict[str, Dict]:
        """
        æµ‹è¯•æ‰€æœ‰æ•°æ®æºè¿æ¥
        
        Returns:
            {
                "akshare": {"status": "ok/error", "message": "...", "latency_ms": 123},
                "mongodb": {"status": "ok/error", "message": "...", "latency_ms": 123},
                "apis": {
                    "northbound": {"status": "ok/error", "message": "...", "data_count": 10},
                    "sector_flow": {...},
                    ...
                }
            }
        """
        import time
        results = {
            "akshare": {"status": "unknown", "message": "", "latency_ms": 0},
            "mongodb": {"status": "unknown", "message": "", "latency_ms": 0},
            "apis": {},
            "test_time": datetime.now().isoformat(),
        }
        
        # æµ‹è¯•AKShare
        if AKSHARE_AVAILABLE:
            results["akshare"]["status"] = "available"
            results["akshare"]["version"] = ak.__version__
            results["akshare"]["message"] = f"AKShare {ak.__version__} å·²å®‰è£…"
        else:
            results["akshare"]["status"] = "not_installed"
            results["akshare"]["message"] = "AKShare æœªå®‰è£…"
        
        # æµ‹è¯•MongoDB
        start = time.time()
        if self.db is not None:
            try:
                self.db.command("ping")
                latency = (time.time() - start) * 1000
                results["mongodb"]["status"] = "connected"
                results["mongodb"]["message"] = f"MongoDB è¿æ¥æ­£å¸¸"
                results["mongodb"]["latency_ms"] = int(latency)
            except Exception as e:
                results["mongodb"]["status"] = "error"
                results["mongodb"]["message"] = str(e)
        else:
            results["mongodb"]["status"] = "not_connected"
            results["mongodb"]["message"] = "MongoDB æœªè¿æ¥"
        
        # æµ‹è¯•å„ä¸ªAPI
        api_tests = [
            ("northbound", self._test_northbound_api),
            ("market_fund_flow", self._test_market_fund_flow_api),
            ("limit_up", self._test_limit_up_api),
            ("dragon_tiger", self._test_dragon_tiger_api),
            ("concept_board", self._test_concept_board_api),
            ("sector_flow", self._test_sector_flow_api),
        ]
        
        for api_name, test_func in api_tests:
            try:
                start = time.time()
                result = test_func()
                latency = (time.time() - start) * 1000
                results["apis"][api_name] = {
                    "status": "ok" if result["success"] else "error",
                    "message": result.get("message", ""),
                    "data_count": result.get("data_count", 0),
                    "latency_ms": int(latency),
                }
            except Exception as e:
                results["apis"][api_name] = {
                    "status": "error",
                    "message": str(e),
                    "data_count": 0,
                    "latency_ms": 0,
                }
        
        return results
    
    def _test_northbound_api(self) -> Dict:
        """æµ‹è¯•åŒ—å‘èµ„é‡‘API"""
        if not AKSHARE_AVAILABLE:
            return {"success": False, "message": "AKShareæœªå®‰è£…"}
        
        import socket
        socket.setdefaulttimeout(10)
        
        df = ak.stock_hsgt_fund_flow_summary_em()
        if df is not None and not df.empty:
            return {"success": True, "message": "åŒ—å‘èµ„é‡‘APIæ­£å¸¸", "data_count": len(df)}
        return {"success": False, "message": "è¿”å›æ•°æ®ä¸ºç©º"}
    
    def _test_market_fund_flow_api(self) -> Dict:
        """æµ‹è¯•å¸‚åœºèµ„é‡‘æµå‘API"""
        if not AKSHARE_AVAILABLE:
            return {"success": False, "message": "AKShareæœªå®‰è£…"}
        
        import socket
        socket.setdefaulttimeout(10)
        
        df = ak.stock_market_fund_flow()
        if df is not None and not df.empty:
            return {"success": True, "message": "å¸‚åœºèµ„é‡‘æµå‘APIæ­£å¸¸", "data_count": len(df)}
        return {"success": False, "message": "è¿”å›æ•°æ®ä¸ºç©º"}
    
    def _test_limit_up_api(self) -> Dict:
        """æµ‹è¯•æ¶¨åœæ± API"""
        if not AKSHARE_AVAILABLE:
            return {"success": False, "message": "AKShareæœªå®‰è£…"}
        
        import socket
        socket.setdefaulttimeout(10)
        
        df = ak.stock_zt_pool_em(date=datetime.now().strftime("%Y%m%d"))
        if df is not None and not df.empty:
            return {"success": True, "message": "æ¶¨åœæ± APIæ­£å¸¸", "data_count": len(df)}
        return {"success": False, "message": "è¿”å›æ•°æ®ä¸ºç©º"}
    
    def _test_dragon_tiger_api(self) -> Dict:
        """æµ‹è¯•é¾™è™æ¦œAPI"""
        if not AKSHARE_AVAILABLE:
            return {"success": False, "message": "AKShareæœªå®‰è£…"}
        
        import socket
        socket.setdefaulttimeout(15)
        
        today = datetime.now().strftime("%Y%m%d")
        df = ak.stock_lhb_detail_em(start_date=today, end_date=today)
        if df is not None and not df.empty:
            return {"success": True, "message": "é¾™è™æ¦œAPIæ­£å¸¸", "data_count": len(df)}
        return {"success": True, "message": "é¾™è™æ¦œAPIæ­£å¸¸ï¼ˆä»Šæ—¥æ— æ•°æ®ï¼‰", "data_count": 0}
    
    def _test_concept_board_api(self) -> Dict:
        """æµ‹è¯•æ¦‚å¿µæ¿å—APIï¼ˆåŒèŠ±é¡ºæ•°æ®æºï¼‰"""
        if not AKSHARE_AVAILABLE:
            return {"success": False, "message": "AKShareæœªå®‰è£…"}
        
        import socket
        socket.setdefaulttimeout(20)
        
        try:
            # ä½¿ç”¨åŒèŠ±é¡ºæ¦‚å¿µèµ„é‡‘æµå‘API
            df = ak.stock_fund_flow_concept(symbol="å³æ—¶")
            if df is not None and not df.empty:
                return {"success": True, "message": "æ¦‚å¿µæ¿å—APIæ­£å¸¸(åŒèŠ±é¡º)", "data_count": len(df)}
            return {"success": False, "message": "è¿”å›æ•°æ®ä¸ºç©º"}
        except Exception as e:
            return {"success": False, "message": f"ç½‘ç»œè¶…æ—¶æˆ–APIé”™è¯¯: {str(e)[:50]}"}
    
    def _test_sector_flow_api(self) -> Dict:
        """æµ‹è¯•æ¿å—èµ„é‡‘æµå‘APIï¼ˆåŒèŠ±é¡ºæ•°æ®æºï¼‰"""
        if not AKSHARE_AVAILABLE:
            return {"success": False, "message": "AKShareæœªå®‰è£…"}
        
        import socket
        socket.setdefaulttimeout(15)
        
        try:
            # ä½¿ç”¨åŒèŠ±é¡ºè¡Œä¸šèµ„é‡‘æµå‘API
            df = ak.stock_fund_flow_industry(symbol="å³æ—¶")
            if df is not None and not df.empty:
                return {"success": True, "message": "æ¿å—èµ„é‡‘æµå‘APIæ­£å¸¸(åŒèŠ±é¡º)", "data_count": len(df)}
            return {"success": False, "message": "è¿”å›æ•°æ®ä¸ºç©º"}
        except Exception as e:
            return {"success": False, "message": f"ç½‘ç»œè¶…æ—¶æˆ–APIé”™è¯¯: {str(e)[:50]}"}


# å…¨å±€å®ä¾‹
real_data_fetcher = RealDataFetcher()

